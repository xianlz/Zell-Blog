[{"content":"一、@Transactional 生效原则 除非特殊配置（比如使用 AspectJ 静态织入实现 AOP），否则只有定义在 public 方法上的 @Transactional 才能生效\n原因是，Spring 默认通过动态代理的方式实现 AOP，对目标方法进行增强，private 方法无法代理到， Spring 自然也无法动态增强事务处理逻辑。\n必须通过代理过的类从外部调用目标方法才能生效。\n在service中未使用@Transaction注解声明的方法中去调用使用了@Transaction的方法，因为默认调用是使用this来调用的，所以该调用是由代理的类的内部进行调用的，所以事务不会再被触发。\n二、事务即便生效也不一定能回滚 当方法出现了异常并且满足一定条件的时候才能进行回滚\n只有异常传播出了标记了 @Transactional 注解的方法，事务才能回滚\n1 2 3 4 5 6 7 8 9 10 11 12 13 try { // This is an around advice: Invoke the next interceptor in the chain. // This will normally result in a target object being invoked. retVal = invocation.proceedWithInvocation(); } catch (Throwable ex) { // target invocation exception completeTransactionAfterThrowing(txInfo, ex); throw ex; } finally { cleanupTransactionInfo(txInfo); } 在 Spring 的 TransactionAspectSupport 里有个 invokeWithinTransaction 方法，里面就是处理事 务的逻辑。可以看到，只有捕获到异常才能进行后续事务处理\n默认情况下，出现 RuntimeException（非受检异常）或 Error 的时候，Spring 才会回滚事务。\n三、请确认事务传播配置是否符合自己的业务逻辑 场景：一个用户注册的操作，会插入一个主用户到用户表，还会注册一个关联的 子用户。我们希望将子用户注册的数据库操作作为一个独立事务来处理，即使失败也不会影 响主流程，即不影响主用户的注册。\n先上原始代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Service public class UserService { @Autowired private UserRepository userRepository; @Autowired private SubUserService subUserService; @Transactional public void createUserInfo(UserDTO userDTO){ User user = userDTO.getUser(); UserDetail userDetail = userDTO.getUserDetail(); userRepository.save(user); userDetail.setUserId(user.getId()); subUserService.createUserDetail(userDetail); } } 1 2 3 4 5 6 7 8 9 10 11 @Service public class SubUserService { @Autowired private SubUserRepository subUserRepository; @Transactional public void createUserDetail(UserDetail userDetail) { subUserRepository.save(userDetail); throw new RuntimeException(\u0026#34;save error ......\u0026#34;); } } 看到这部分代码，当我们调用时会发现，不论是subUserRepository.save(userDetail) ，还是userRepository.save(user)都回滚了，这个是正常操作。如果要满足场景subUserRepository.save(userDetail)回滚，而userRepository.save(user)不会滚。我们根据前面回滚需要满足的条件中随便破坏一条不就完事了吗。所以我选择将subUserService.createUserDetail(userDetail)抛出的异常给捕获了不就完事了吗，然后走你。\n1 2 3 4 5 6 try { userDetail.setUserId(user.getId()); subUserService.createUserDetail(userDetail); } catch (Exception e) { System.out.println(\u0026#34;not rollback this method.......\u0026#34;); } but 、but、but还是回滚了，这是怎么回事呢。\n原因：@Transactional标注方法调用另一个@Transactional标注方法方法时，默认使用的事务传播机制是使用同一个事物，所以subUserRepository.save(userDetail)回滚时，因为userRepository.save(user)和它使用的是同一个事务，那么它没理由不回滚。\nso \u0026hellip;\u0026hellip; 需要改一下事务的传播机制 ， 即在你要调用的事务方法声明该事务是沿用调用方的事务还是自己新开一个事务\n1 2 3 4 5 @Transactional(propagation = Propagation.REQUIRES_NEW) public void createUserDetail(UserDetail userDetail) { subUserRepository.save(userDetail); throw new RuntimeException(\u0026#34;save error ......\u0026#34;); } ","date":"2025-10-21T20:58:44+08:00","image":"https://zell.zone/p/%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98-%E4%BB%A3%E7%A0%81%E7%AF%87%E4%BA%8B%E5%8A%A1/img/1_hu_9e4e9426a2fab57b.jpg","permalink":"https://zell.zone/p/%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98-%E4%BB%A3%E7%A0%81%E7%AF%87%E4%BA%8B%E5%8A%A1/","title":"业务开发问题 代码篇(事务)"},{"content":"对于 HTTP 调用，虽然应用层走的是 HTTP 协议，但网络层面始终是 TCP/IP 协议。 TCP/IP 是面向连接的协议，在传输数据之前需要建立连接。几乎所有的网络框架都会提供 这么两个超时参数：\n连接超时参数 ConnectTimeout，让用户配置建连阶段的最长等待时间；\n读取超时参数 ReadTimeout，用来控制从 Socket 上读取数据的最长等待时间。\n连接超时配置得特别长，比如 60 秒。一般来说，TCP 三次握手建立连接需要的时间非 常短，通常在毫秒级最多到秒级，不可能需要十几秒甚至几十秒。如果很久都无法建 连，很可能是网络或防火墙配置的问题。这种情况下，如果几秒连接不上，那么可能永 远也连接不上。因此，设置特别长的连接超时意义不大，将其配置得短一些（比如 1~5 秒）即可。如果是纯内网调用的话，这个参数可以设置得更短，在下游服务离线无法连 接的时候，可以快速失败。\n误区一：Read timed out了，以为服务端不会再往下执行了，实际上服务端在五秒后依然执行完毕了。 接下来展示一个小代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 @RestController @RequestMapping(\u0026#34;clientreadtimeout\u0026#34;) @Slf4j public class HttpDemo01 { public String getResponse(String path , int connectTime , int readTime) throws Exception { URL url = new URL(\u0026#34;http://localhost:8001/clientreadtimeout\u0026#34;+path); HttpURLConnection con = (HttpURLConnection) url.openConnection(); con.setRequestMethod(\u0026#34;GET\u0026#34;); con.setConnectTimeout(connectTime); con.setReadTimeout(readTime); return con.getResponseMessage(); } @GetMapping(\u0026#34;/client\u0026#34;) public String client() throws Exception { // 连接一秒，读取内容两秒 ，在请求的服务端设置5秒 return getResponse(\u0026#34;/service\u0026#34; , 1000 , 2000); } @GetMapping(\u0026#34;/service\u0026#34;) public String service(){ try { TimeUnit.SECONDS.sleep(5); } catch (InterruptedException e) { throw new RuntimeException(e); } System.out.println(\u0026#34;服务端处理请求完毕\u0026#34;); return \u0026#34;请求成功\u0026#34;; } } 上面模拟了客户端访问服务端的情况，并且在服务端的处理时长设置成了5秒，结局显而易见\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 java.net.SocketTimeoutException: Read timed out at java.base/sun.nio.ch.NioSocketImpl.timedRead(NioSocketImpl.java:288) ~[na:na] at java.base/sun.nio.ch.NioSocketImpl.implRead(NioSocketImpl.java:314) ~[na:na] at java.base/sun.nio.ch.NioSocketImpl.read(NioSocketImpl.java:355) ~[na:na] at java.base/sun.nio.ch.NioSocketImpl$1.read(NioSocketImpl.java:808) ~[na:na] at java.base/java.net.Socket$SocketInputStream.read(Socket.java:966) ~[na:na] at java.base/java.io.BufferedInputStream.fill(BufferedInputStream.java:244) ~[na:na] at java.base/java.io.BufferedInputStream.read1(BufferedInputStream.java:284) ~[na:na] at java.base/java.io.BufferedInputStream.read(BufferedInputStream.java:343) ~[na:na] at java.base/sun.net.www.http.HttpClient.parseHTTPHeader(HttpClient.java:826) ~[na:na] .................. 服务端处理请求完毕 误区二：认为读取超时只是 Socket 网络层面的概念，是数据传输的最长耗时，故将其 配置得非常短，比如 100 毫秒。 其实，发生了读取超时，网络层面无法区分是服务端没有把数据返回给客户端，还是数据在 网络上耗时较久或丢包。 但，因为 TCP 是先建立连接后传输数据，对于网络情况不是特别糟糕的服务调用，通常可 以认为出现连接超时是网络问题或服务不在线，而出现读取超时是服务处理超时。确切地 说，读取超时指的是，向 Socket 写入数据后，我们等到 Socket 返回数据的超时时间，其 中包含的时间或者说绝大部分的时间，是服务端处理业务逻辑的时间。\n误区三：认为超时时间越长任务接口成功率就越高，将读取超时参数配置得太长。 进行 HTTP 请求一般是需要获得结果的，属于同步调用。如果超时时间很长，在等待服务 端返回数据的同时，客户端线程（通常是 Tomcat 线程）也在等待，当下游服务出现大量 超时的时候，程序可能也会受到拖累创建大量线程，最终崩溃。 对定时任务或异步任务来说，读取超时配置得长些问题不大。但面向用户响应的请求或是微 服务短平快的同步接口调用，并发量一般较大，我们应该设置一个较短的读取超时时间，以 防止被下游服务拖慢，通常不会设置超过 30 秒的读取超时。 你可能会说，如果把读取超时设置为 2 秒，服务端接口需要 3 秒，岂不是永远都拿不到执 行结果了？的确是这样，因此设置读取超时一定要根据实际情况，过长可能会让下游抖动影响到自己，过短又可能影响成功率。甚至，有些时候我们还要根据下游服务的 SLA，为不 同的服务端接口设置不同的客户端读取超时。\n","date":"2025-10-20T22:10:16+08:00","image":"https://zell.zone/p/%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98-%E4%BB%A3%E7%A0%81%E7%AF%87http%E8%B0%83%E7%94%A8/img/1_hu_34431e89b383669.jpg","permalink":"https://zell.zone/p/%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98-%E4%BB%A3%E7%A0%81%E7%AF%87http%E8%B0%83%E7%94%A8/","title":"业务开发问题 代码篇(HTTP调用)"},{"content":"连接池一般对外提供获得连接、归还连接的接口给客户端使 用，并暴露最小空闲连接数、最大连接数等可配置参数，在内部则实现连接建立、连接心跳 保持、连接管理、空闲连接回收、连接可用性检测等功能。如下图示\n我们先看一下涉及 TCP 连接的客户端 SDK，对外提供 API 的三种方式。在面对各种三方客 户端的时候，只有先识别出其属于哪一种，才能理清楚使用方式。 连接池和连接分离的 API：有一个 XXXPool 类负责连接池实现，先从其获得连接 XXXConnection，然后用获得的连接进行服务端请求，完成后使用者需要归还连接。通 常，XXXPool 是线程安全的，可以并发获取和归还连接，而 XXXConnection 是非线程 安全的。对应到连接池的结构示意图中，XXXPool 就是右边连接池那个框，左边的客户 端是我们自己的代码。 内部带有连接池的 API：对外提供一个 XXXClient 类，通过这个类可以直接进行服务端 请求；这个类内部维护了连接池，SDK 使用者无需考虑连接的获取和归还问题。一般而 言，XXXClient 是线程安全的。对应到连接池的结构示意图中，整个 API 就是蓝色框包 裹的部分。 非连接池的 API：一般命名为 XXXConnection，以区分其是基于连接池还是单连接的， 而不建议命名为 XXXClient 或直接是 XXX。直接连接方式的 API 基于单一连接，每次使 用都需要创建和断开连接，性能一般，且通常不是线程安全的。对应到连接池的结构示 意图中，这种形式相当于没有右边连接池那个框，客户端直接连接服务端创建连接。 创建连接池的时候很可能一次性创建了多个连接，大多数连接池考虑到性能，会在初始 化的时候维护一定数量的最小连接（毕竟初始化连接池的过程一般是一次性的），可以 直接使用。如果每次使用连接池都按需创建连接池，那么很可能你只用到一个连接，但 是创建了 N 个连接。 连接池一般会有一些管理模块，也就是连接池的结构示意图中的绿色部分。举个例子， 大多数的连接池都有闲置超时的概念。连接池会检测连接的闲置时间，定期回收闲置的 连接，把活跃连接数降到最低（闲置）连接的配置值，减轻服务端的压力。一般情况 下，闲置连接由独立线程管理，启动了空闲检测的连接池相当于还会启动一个线程。此 外，有些连接池还需要独立线程负责连接保活等功能。因此，启动一个连接池相当于启 动了 N 个线程。\n连接池的配置不是一成不变的 为方便根据容量规划设置连接处的属性，连接池提供了许多参数，包括最小（闲置）连接、 最大连接、闲置连接生存时间、连接生存时间等。其中，最重要的参数是最大连接数，它决 定了连接池能使用的连接数量上限，达到上限后，新来的请求需要等待其他请求释放连接。 但，最大连接数不是设置得越大越好。如果设置得太大，不仅仅是客户端需要耗费过多的资 源维护连接，更重要的是由于服务端对应的是多个客户端，每一个客户端都保持大量的连接，会给服务端带来更大的压力。这个压力又不仅仅是内存压力，可以想一下如果服务端的 网络模型是一个 TCP 连接一个线程，那么几千个连接意味着几千个线程，如此多的线程会 造成大量的线程切换开销。当然，连接池最大连接数设置得太小，很可能会因为获取连接的等待时间太长，导致吞吐量 低下，甚至超时无法获取连接。\n","date":"2025-10-19T21:03:14+08:00","image":"https://zell.zone/p/%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98-%E4%BB%A3%E7%A0%81%E7%AF%87%E8%BF%9E%E6%8E%A5%E6%B1%A0/img/1_hu_b42c703b3e855ff1.jpg","permalink":"https://zell.zone/p/%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98-%E4%BB%A3%E7%A0%81%E7%AF%87%E8%BF%9E%E6%8E%A5%E6%B1%A0/","title":"业务开发问题 代码篇(连接池)"},{"content":"问题一：在tomcat中的工作线程是复用的，当我们使用ThreadLocal来传递当前线程的变量时，可能会出现信息错乱的问题 ThreadLocal是线程安全的，这个毋庸置疑；但是当ThreadLocal 加上线程池时就不一定是安全的了\n话不多说，直接上代码\n创建spring-boot项目\n在application.properties文件中配置\n1 2 3 server.port=8001 spring.application.name=error-thread server.tomcat.threads.max=1 # 模拟达到当访问人数达到最大线程时 测试代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 private final ThreadLocal\u0026lt;Integer\u0026gt; threadLocal = ThreadLocal.withInitial(() -\u0026gt; null); @GetMapping(\u0026#34;/getUser\u0026#34;) public String getUser(@RequestParam(\u0026#34;uId\u0026#34;) Integer uId) { //设置值前先查询一次 String before = Thread.currentThread().getName() + \u0026#34;:\u0026#34; + threadLocal.get(); System.out.println(\u0026#34;before\u0026#34; + before); threadLocal.set(uId); //设置完值后在查询一次 String after = Thread.currentThread().getName() + \u0026#34;:\u0026#34; + threadLocal.get(); System.out.println(\u0026#34;after\u0026#34; + after); return \u0026#34;\u0026#34;; } 访问http://localhost:8001/getUser?uId=1 以及 http://localhost:8001/getUser?uId=2，观察打印日志\n1 2 3 4 beforehttp-nio-8001-exec-1:null afterhttp-nio-8001-exec-1:1 beforehttp-nio-8001-exec-1:1 afterhttp-nio-8001-exec-1:2 观察上述日志可知，第一次请求没有问题，但是在第二次请求时却能获得上一个请求的数据，这样肯定会导致信息错乱\n解决办法:每次使用完后都需要清除信息\nprivate final ThreadLocal threadLocal = ThreadLocal.withInitial(() -\u0026gt; null);\n1 2 3 4 5 6 7 8 9 10 11 12 @GetMapping(\u0026#34;/getUser\u0026#34;) public String getUser(@RequestParam(\u0026#34;uId\u0026#34;) Integer uId) { //设置值前先查询一次 String before = Thread.currentThread().getName() + \u0026#34;:\u0026#34; + threadLocal.get(); System.out.println(\u0026#34;before\u0026#34; + before); threadLocal.set(uId); //设置完值后在查询一次 String after = Thread.currentThread().getName() + \u0026#34;:\u0026#34; + threadLocal.get(); System.out.println(\u0026#34;after\u0026#34; + after); threadLocal.remove(); return \u0026#34;\u0026#34;; } 日志：\n1 2 3 4 beforehttp-nio-8001-exec-1:null afterhttp-nio-8001-exec-1:1 beforehttp-nio-8001-exec-1:null afterhttp-nio-8001-exec-1:2 这个时候就正常了\n问题二：ConcurrentHashMap的线程不安全事件。 都知道ConcurrentHashMap是线程安全的键值对存储容器，但是当你使用不规范的时候，也是会发生意外的。\nConcurrentHashMap 的线程安全保证：\n单个操作是原子的（如 put, get, putAll） 内部结构不会损坏 不会出现 ConcurrentModificationException 但无法保证：\n复合操作的原子性 业务逻辑的正确性 请看下面代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 private static int ITEM_NUM = 1000; private static int WORK_THREAD = 10; private ConcurrentHashMap\u0026lt;String, Long\u0026gt; getData(int count) { return LongStream.rangeClosed(1, count) .boxed() .collect( Collectors.toConcurrentMap(i -\u0026gt; UUID.randomUUID().toString() , Function.identity() , (o1, o2) -\u0026gt; o1 , ConcurrentHashMap::new)); } @GetMapping(\u0026#34;/putData\u0026#34;) public String putData() throws InterruptedException { ConcurrentHashMap\u0026lt;String, Long\u0026gt; data = getData(900); log.info(\u0026#34;初始化完后现有数量：\u0026#34; + data.size()); ForkJoinPool forkJoinPool = new ForkJoinPool(WORK_THREAD); List\u0026lt;Callable\u0026lt;Void\u0026gt;\u0026gt; tasks = IntStream.rangeClosed(1, 10) .mapToObj(i -\u0026gt; (Callable\u0026lt;Void\u0026gt;) () -\u0026gt; { // synchronized (data) { int size = ITEM_NUM - data.size(); log.info(\u0026#34;剩余待添加元素：\u0026#34; + size); if (size \u0026gt; 0) { data.putAll(getData(size)); } //} return null; }) .collect(Collectors.toList()); List\u0026lt;Future\u0026lt;Void\u0026gt;\u0026gt; futures = forkJoinPool.invokeAll(tasks); forkJoinPool.shutdown(); forkJoinPool.awaitTermination(1, TimeUnit.HOURS); log.info(\u0026#34;添加完成后元素数量：\u0026#34; + data.size()); return \u0026#34;\u0026#34;; } 这个demo是使用十个线程往一个已经有900个元素的ConcurrentHashMap填充到1000。打印结果发现最后添加了1900个元素，问题就在与data.size() 和 data.putAll(getData(size))操作并不是原子性的，所以每个线程都可能得到其他线程还未添加进ConcurrentHashMap之前的size，导致出现了问题。\n解决办法：\n放开同步代码块，synchronized (data)，这样就能保证同步代码块内的操作每次只有一个线程能访问。但是这样也就打打的降低了效率，而且也没有使用上ConcurrentHashMap的特性。\n接下来我们再举一个例子来对比说明ConcurrentHashMap的妙用。\n案例：\n使用10个线程对10000000数量进行词频分析\n先上同步代码块的代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 //循环次数 private static int LOOP_COUNT = 10000000; //线程数量 private static int THREAD_COUNT = 10; //元素数量 private static int ITEM_COUNT = 1000; private Map\u0026lt;String, Long\u0026gt; normalUse() throws InterruptedException { ConcurrentHashMap\u0026lt;String, Long\u0026gt; freqs = new ConcurrentHashMap\u0026lt;\u0026gt;(ITEM_COUNT); ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT); forkJoinPool.execute( () -\u0026gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -\u0026gt; { String key = \u0026#34;item\u0026#34; + ThreadLocalRandom.current().nextInt(ITEM_COUNT); synchronized (freqs) { if (freqs.containsKey(key)) { freqs.put(key, freqs.get(key) + 1); } else { freqs.put(key, 1L); } } }) ); forkJoinPool.shutdown(); forkJoinPool.awaitTermination(1, TimeUnit.HOURS); return freqs; } 再看看使用ConcurrentHashMap中自带的原子操作实现查询并插入的\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 private Map\u0026lt;String, Long\u0026gt; goodUse() throws InterruptedException { ConcurrentHashMap\u0026lt;String, LongAdder\u0026gt; freqs = new ConcurrentHashMap\u0026lt;\u0026gt;(ITEM_COUNT); ForkJoinPool forkJoinPool = new ForkJoinPool(THREAD_COUNT); forkJoinPool.execute(() -\u0026gt; IntStream.rangeClosed(1, LOOP_COUNT).parallel().forEach(i -\u0026gt; { String key = \u0026#34;item\u0026#34; + ThreadLocalRandom.current().nextInt(ITEM_COUNT); freqs.computeIfAbsent(key, k -\u0026gt; new LongAdder()).increment(); })); forkJoinPool.shutdown(); forkJoinPool.awaitTermination(1, TimeUnit.HOURS); return freqs.entrySet().stream().collect(Collectors.toMap( e -\u0026gt; e.getKey(), e -\u0026gt; e.getValue().longValue()) ); } computeIfAbsent()方法表示如果该key未被发现，则进行初始化，否则执行其他操作\n对比效率\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @GetMapping(\u0026#34;/comparison\u0026#34;) public String comparison() throws InterruptedException { StopWatch stopWatch = new StopWatch(); stopWatch.start(\u0026#34;normaluse\u0026#34;); Map\u0026lt;String, Long\u0026gt; normaluse = normalUse(); stopWatch.stop(); //校验元素数量 Assert.isTrue(normaluse.size() == ITEM_COUNT, \u0026#34;normaluse size error\u0026#34;); //校验累计总数 Assert.isTrue(normaluse.entrySet().stream() .mapToLong(item -\u0026gt; item.getValue()).reduce(0, Long::sum) == LOOP_COUNT , \u0026#34;normaluse count error\u0026#34;); stopWatch.start(\u0026#34;gooduse\u0026#34;); Map\u0026lt;String, Long\u0026gt; gooduse = goodUse(); stopWatch.stop(); Assert.isTrue(gooduse.size() == ITEM_COUNT, \u0026#34;gooduse size error\u0026#34;); Assert.isTrue(gooduse.entrySet().stream() .mapToLong(item -\u0026gt; item.getValue()) .reduce(0, Long::sum) == LOOP_COUNT , \u0026#34;gooduse count error\u0026#34;); log.info(stopWatch.prettyPrint()); return \u0026#34;\u0026#34;; } 得到结果\n1 2 3 4 5 ---------------------------------------- Seconds % Task name ---------------------------------------- 3.2756417 91% normaluse 0.3094116 09% gooduse 效果显著\n接下来我们看看为什么computeIfAbsent这么快\n首先看看computeIfAbsent方法内的大致逻辑\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public V computeIfAbsent(K key, Function\u0026lt;? super K, ? extends V\u0026gt; mappingFunction) { int hash = spread(key.hashCode()); Node\u0026lt;K,V\u0026gt;[] tab; while (true) { // 找到对应的bucket（数组槽位） int i = (tab.length - 1) \u0026amp; hash; Node\u0026lt;K,V\u0026gt; f = tabAt(tab, i); if (f == null) { // 空bucket：使用CAS创建新节点 if (casTabAt(tab, i, null, new Node\u0026lt;K,V\u0026gt;(hash, key, value))) break; } else { // 非空bucket：同步这个bucket synchronized (f) { // 在bucket内链表/树中查找或插入 // 只锁这个bucket，不影响其他bucket } } } } 从上面可以看到，synchronized同步代码块的范围很小，只锁住了key的所在bucket。而由我们自己去加锁的方式去实现的添加则是将整个map都锁上了，所以对于所有操作都是串行的。\n问题三：不考虑实际读写情况滥用CopyOnWriteArrayList，导致接口超时。 我们写一段测试代码，来比较下使用 CopyOnWriteArrayList 和普通加锁方式 ArrayList 的读写性能吧。在这段代码中我们针对并发读和并发写分别写了一个测试方法，测试两者一 定次数的写或读操作的耗时。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //测试并发写的性能 @GetMapping(\u0026#34;write\u0026#34;) public String testWrite() { CopyOnWriteArrayList\u0026lt;Integer\u0026gt; copyOnWriteArrayList = new CopyOnWriteArrayList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; synchronizedList = Collections.synchronizedList(new ArrayList\u0026lt;Integer\u0026gt;()); StopWatch stopWatch = new StopWatch(); int loopCount = 100000; stopWatch.start(\u0026#34;Write:copyOnWriteArrayList\u0026#34;); //循环100000次并发往CopyOnWriteArrayList写入随机元素 IntStream.rangeClosed(1,loopCount).parallel().forEach(__-\u0026gt;copyOnWriteArrayList.add(ThreadLocalRandom.current().nextInt(loopCount))); stopWatch.stop(); stopWatch.start(\u0026#34;Write:synchronizedList\u0026#34;); //循环100000次并发往synchronizedList写入随机元素 IntStream.rangeClosed(1,loopCount).parallel().forEach(__-\u0026gt;synchronizedList.add(ThreadLocalRandom.current().nextInt(loopCount))); stopWatch.stop(); log.info(stopWatch.prettyPrint()); return \u0026#34;success\u0026#34;; } 结果\n1 2 3 4 5 ---------------------------------------- Seconds % Task name ---------------------------------------- 3.5899543 99% Write:copyOnWriteArrayList 0.024815 01% Write:synchronizedList 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 //测试并发写的性能 @GetMapping(\u0026#34;read\u0026#34;) public String testRead() { CopyOnWriteArrayList\u0026lt;Integer\u0026gt; copyOnWriteArrayList = new CopyOnWriteArrayList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; synchronizedList = Collections.synchronizedList(new ArrayList\u0026lt;Integer\u0026gt;()); //先添加号元素 addAll(copyOnWriteArrayList); addAll(synchronizedList); StopWatch stopWatch = new StopWatch(); int loopCount = 1000000; stopWatch.start(\u0026#34;Read:copyOnWriteArrayList\u0026#34;); //循环100000次并发从CopyOnWriteArrayList查询元素 IntStream.rangeClosed(1, loopCount).parallel().forEach(__ -\u0026gt; copyOnWriteArrayList.get(ThreadLocalRandom.current().nextInt(loopCount))); stopWatch.stop(); stopWatch.start(\u0026#34;Read:synchronizedList\u0026#34;); //循环100000次并发从synchronizedList查询元素 IntStream.rangeClosed(1, loopCount).parallel().forEach(__ -\u0026gt; synchronizedList.get(ThreadLocalRandom.current().nextInt(loopCount))); stopWatch.stop(); log.info(stopWatch.prettyPrint()); return \u0026#34;success\u0026#34;; } 结果\n1 2 3 4 5 ---------------------------------------- Seconds % Task name ---------------------------------------- 0.0091182 04% Read:copyOnWriteArrayList 0.2139405 96% Read:synchronizedList 从上面代码来看CopyOnWriteArrayList和普通加锁方式 ArrayList 的读写性能是两种截然相反的结果。CopyOnWriteArrayList在写操作时性能时简直是太糟糕了，而普通加锁方式 ArrayList 在读时性能又比CopyOnWriteArrayList逊色太多。所以要评估自己需求，来决定是否要使用CopyOnWriteArrayList。\n为什么CopyOnWriteArrayList的写入性能会这么差呢？\n原因就是它每次执行插入操作时都会进行复制Object[] newElements = Arrays.copyOf(elements, len + 1);\n问题四：创建线程池Executors不规范导致程序出现OOM eg1：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * newFixedThreadPool 创建线程池时的OOM */ public void test2(){ ExecutorService executorService = Executors.newFixedThreadPool(1); for (int i = 0; i \u0026lt; 100000000; i++) { executorService.execute(()-\u0026gt;{ String payload = IntStream.rangeClosed(1,1000000) .mapToObj(__-\u0026gt;\u0026#34;a\u0026#34;) .collect(Collectors.joining(\u0026#34;\u0026#34;)) + UUID.randomUUID().toString(); try { TimeUnit.HOURS.sleep(1); } catch (InterruptedException e) { throw new RuntimeException(e); } System.out.println(payload); }); } } 由newFixedThreadPool()创建线程的参数如下\n1 2 3 4 5 public static ExecutorService newFixedThreadPool(int nThreads) { return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()); } 其中new LinkedBlockingQueue\u0026lt;Runnable\u0026gt;()的大小是Integer.MAX_VALUE ， 当任务量多并且任务的处理时间比较慢时，LinkedBlockingQueue带运行任务队列中数量激增，导致OOM\neg2\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 /** * newCachedThreadPool 创建线程池时的OOM */ public void test3(){ ExecutorService executorService = Executors.newCachedThreadPool(); for (int i = 0; i \u0026lt; 100000000; i++) { executorService.execute(()-\u0026gt;{ String payload = IntStream.rangeClosed(1,1000000) .mapToObj(__-\u0026gt;\u0026#34;a\u0026#34;) .collect(Collectors.joining(\u0026#34;\u0026#34;)) + UUID.randomUUID().toString(); try { TimeUnit.HOURS.sleep(1); } catch (InterruptedException e) { throw new RuntimeException(e); } System.out.println(payload); }); } } 由newCachedThreadPool()创建线程的参数如下\n1 2 3 4 5 public static ExecutorService newCachedThreadPool() { return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue\u0026lt;Runnable\u0026gt;()); } SynchronousQueue 是一个没有存储空间的阻塞队列 ,而且这里设置的最大线程数是Integer.MAX_VALUE，当任务量多并且任务的处理时间比较慢时，会一直创建线程，导致OOM。\n我们定义一个方法来监控线程池状态\n1 2 3 4 5 6 7 8 9 10 public void printStatus(ThreadPoolExecutor threadPoolExecutor) { Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -\u0026gt; { System.out.println(\u0026#34;========================\u0026#34;); System.out.println(\u0026#34;线程数:\u0026#34; + threadPoolExecutor.getPoolSize()); System.out.println(\u0026#34;活跃线程数:\u0026#34; + threadPoolExecutor.getActiveCount()); System.out.println(\u0026#34;完成了多少任务:\u0026#34; + threadPoolExecutor.getCompletedTaskCount()); System.out.println(\u0026#34;队列中还有多少积压:\u0026#34; + threadPoolExecutor.getQueue().size()); System.out.println(\u0026#34;========================\u0026#34;); }, 0, 1, TimeUnit.SECONDS); } 自定义一个线程池\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 public void test4() throws InterruptedException { //具有 2 个核心线程、5 个最大线程、使用容量为 10 //的 ArrayBlockingQueue 阻塞队列作为工作队列，使用默认的 AbortPolicy 拒绝策略，也 //就是任务添加到线程池失败会抛出 RejectedExecutionException。此外，我们借助了 //Jodd 类库的 ThreadFactoryBuilder 方法来构造一个线程工厂，实现线程池线程的自定义 //命名。 AtomicInteger atomicInteger = new AtomicInteger(); ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor( 2, 5, 5, TimeUnit.SECONDS , new ArrayBlockingQueue\u0026lt;\u0026gt;(10) , new ThreadFactoryBuilder().setNameFormat(\u0026#34;demo-threadpool-%d\u0026#34;).get() , new ThreadPoolExecutor.AbortPolicy() ); printStatus(threadPoolExecutor); IntStream.rangeClosed(1,20).forEach(i-\u0026gt;{ try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new RuntimeException(e); } int id = atomicInteger.incrementAndGet(); try { threadPoolExecutor.submit(()-\u0026gt;{ System.out.println(id + \u0026#34;start。。。。。\u0026#34;); try { TimeUnit.SECONDS.sleep(10); } catch (InterruptedException e) { throw new RuntimeException(e); } System.out.println(id + \u0026#34;end。。。。。\u0026#34;); }); } catch (Exception e) { System.out.println(id + \u0026#34;error submit。。。。。\u0026#34;); throw new RuntimeException(e); } }); TimeUnit.SECONDS.sleep(60); } 运行结果打印\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 ======================== 线程数:0 活跃线程数:0 完成了多少任务:0 队列中还有多少积压:0 ======================== 1start。。。。。 ======================== 线程数:1 活跃线程数:1 完成了多少任务:0 队列中还有多少积压:0 ======================== ....... 省略一部分 ======================== 线程数:2 活跃线程数:2 完成了多少任务:2 队列中还有多少积压:8 ======================== ======================== 线程数:2 活跃线程数:2 完成了多少任务:2 队列中还有多少积压:9 ======================== ======================== 线程数:2 活跃线程数:2 完成了多少任务:2 队列中还有多少积压:10 ======================== 15start。。。。。 ======================== 线程数:3 活跃线程数:3 完成了多少任务:2 队列中还有多少积压:10 ======================== 16start。。。。。 ======================== 线程数:4 活跃线程数:4 完成了多少任务:2 队列中还有多少积压:10 ======================== 17start。。。。。 ======================== 线程数:5 活跃线程数:5 完成了多少任务:2 队列中还有多少积压:10 ======================== 18error submit。。。。。 Exception in thread \u0026#34;main\u0026#34; java.lang.RuntimeException: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.FutureTask@30946e09[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@6e5e91e4[Wrapped task = com.error.thread.thread.ThreadDemo4$$Lambda$24/0x000001eb1b003450@2cdf8d8a]] rejected from java.util.concurrent.ThreadPoolExecutor@5cb0d902[Running, pool size = 5, active threads = 5, queued tasks = 10, completed tasks = 2] at com.error.thread.thread.ThreadDemo4.lambda$test4$8(ThreadDemo4.java:127) at java.base/java.util.stream.Streams$RangeIntSpliterator.forEachRemaining(Streams.java:104) at java.base/java.util.stream.IntPipeline$Head.forEach(IntPipeline.java:617) at com.error.thread.thread.ThreadDemo4.test4(ThreadDemo4.java:107) at com.error.thread.thread.ThreadDemo4.main(ThreadDemo4.java:137) Caused by: java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.FutureTask@30946e09[Not completed, task = java.util.concurrent.Executors$RunnableAdapter@6e5e91e4[Wrapped task = com.error.thread.thread.ThreadDemo4$$Lambda$24/0x000001eb1b003450@2cdf8d8a]] rejected from java.util.concurrent.ThreadPoolExecutor@5cb0d902[Running, pool size = 5, active threads = 5, queued tasks = 10, completed tasks = 2] at java.base/java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2065) at java.base/java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:833) at java.base/java.util.concurrent.ThreadPoolExecutor.execute(ThreadPoolExecutor.java:1365) at java.base/java.util.concurrent.AbstractExecutorService.submit(AbstractExecutorService.java:123) at com.error.thread.thread.ThreadDemo4.lambda$test4$8(ThreadDemo4.java:116) ... 4 more ....... 省略一部分 ======================== 线程数:2 活跃线程数:0 完成了多少任务:17 队列中还有多少积压:0 ======================== ⭐⭐⭐根据自定义线程池检查结果，我们可以总结出线程池的执行逻辑如下 当有任务提交到线程池中，使用核心线程执行 当核心线程使用完后再有任务提交到线程池中时，不会立马扩充线程，而是会将任务先加入到工作队列中 当工作队列到达指定的容量大小时，会开始扩充线程，最大数量不可超过指定最大线程数 当达到最大线程数还有任务提交时，则会使用指定的拒绝策略。 最后当线程数大于核心线程数时，且在指定keepAliveTime内没有任务提交过来，则会进行收缩核心线程数到指定数量。 由于线程池在工作队列满了无法入队的情况下会扩容线程池，那么我们是否可以重写队 列的 offer 方法，造成这个队列已满的假象呢？\n自定义工作队列\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 public class MyArrayBlockingQueue\u0026lt;E\u0026gt; extends ArrayBlockingQueue\u0026lt;E\u0026gt; { // 持有线程池引用，用于获取实时线程数和最大线程数 private ThreadPoolExecutor threadPoolExecutor; public MyArrayBlockingQueue(int capacity, ThreadPoolExecutor threadPoolExecutor) { super(capacity); this.threadPoolExecutor = threadPoolExecutor; } public MyArrayBlockingQueue(int capacity, boolean fair, ThreadPoolExecutor threadPoolExecutor) { super(capacity, fair); this.threadPoolExecutor = threadPoolExecutor; } public MyArrayBlockingQueue(int capacity, boolean fair, Collection c, ThreadPoolExecutor threadPoolExecutor) { super(capacity, fair, c); this.threadPoolExecutor = threadPoolExecutor; } @Override public boolean offer(E o) { Objects.requireNonNull(o); if (threadPoolExecutor.getMaximumPoolSize() \u0026gt; threadPoolExecutor.getPoolSize()) { return false; } return super.offer(o); } 创建线程池\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public static ThreadPoolExecutor newMyThreadPoolExecutor() { /** * 由于线程池在工作队列满了无法入队的情况下会扩容线程池，那么我们是否可以重写队 * 列的 offer 方法，造成这个队列已满的假象呢？ */ ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(2, 5, 5, TimeUnit.SECONDS , new ArrayBlockingQueue\u0026lt;\u0026gt;(10) // 临时的，等下通过反射进行替换 , new ThreadFactoryBuilder().setNameFormat(\u0026#34;demo-threadpool-%d\u0026#34;).get() , new ThreadPoolExecutor.AbortPolicy() ); //通过反射替换工作队列 MyArrayBlockingQueue workQueue = new MyArrayBlockingQueue\u0026lt;\u0026gt;(10, threadPoolExecutor); try { Field workQueueField = ThreadPoolExecutor.class.getDeclaredField(\u0026#34;workQueue\u0026#34;); workQueueField.setAccessible(true); workQueueField.set(threadPoolExecutor , workQueue); } catch (Exception e) { throw new RuntimeException(\u0026#34;替换队列失败\u0026#34;, e); } return threadPoolExecutor; } ⭐⭐⭐要根据任务的“轻重缓急”来指定线程池的核心 参数，包括线程数、回收策略和任务队列： 对于执行比较慢、数量不大的 IO 任务，或许要考虑更多的线程数，而不需要太大的队 列。 而对于吞吐量较大的计算型任务，线程数量不宜过多，可以是 CPU 核数或核数 *2（理 由是，线程一定调度到某个 CPU 进行执行，如果任务本身是 CPU 绑定的任务，那么过 多的线程只会增加线程切换的开销，并不能提升吞吐量），但可能需要较长的队列来做 缓冲。\n","date":"2025-10-08T20:49:13+08:00","image":"https://zell.zone/p/%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98-%E4%BB%A3%E7%A0%81%E7%AF%87%E7%BA%BF%E7%A8%8B/img/1_hu_c994728578ae7e8d.jpg","permalink":"https://zell.zone/p/%E4%B8%9A%E5%8A%A1%E5%BC%80%E5%8F%91%E9%97%AE%E9%A2%98-%E4%BB%A3%E7%A0%81%E7%AF%87%E7%BA%BF%E7%A8%8B/","title":"业务开发问题-代码篇(线程)"},{"content":"一、简介 1. 什么是 Drools Drools 是一款由 JBoss 组织提供的基于 Java 的开源规则引擎，属于业务规则管理系统（BRMS）。其核心思想是将业务规则从硬编码中分离，以规则脚本形式存储（如文件、数据库），支持动态配置与更新，无需修改代码或重启服务即可生效，适用于业务规则复杂且多变的场景（如电商优惠规则、金融风控、社保审批等）。\n2. 核心组件 Drools 规则引擎主要由三部分构成：\nWorking Memory（工作内存）：存储业务数据（Fact 对象），规则引擎从这里获取数据并与规则匹配。\nRule Base（规则库）：存放所有定义的业务规则，规则加载后会被解析并存储到规则库中。\nInference Engine（推理引擎）\n：核心执行模块，包含：\nPattern Matcher（匹配器）：将规则库中的规则与工作内存中的 Fact 对象进行模式匹配。 Agenda（议程）：存放匹配成功的规则，按优先级排序等待执行。 Execution Engine（执行引擎）：执行议程中排序后的规则。 3. 关键概念 Fact（事实）：普通 Java Bean 插入工作内存后的对象，是应用与规则引擎的数据交互桥梁。 DRL（Drools Rule Language）：Drools 规则定义语言，用于编写规则脚本，支持声明式语法。 KIE（Knowledge Is Everything）：Drools 生态的核心框架，提供规则的编译、部署、执行等统一 API（如 KieSession、KieContainer 等）。 二、创建项目 依赖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 \u0026lt;parent\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.0.5\u0026lt;/version\u0026gt; \u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; \u0026lt;/parent\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;17\u0026lt;/java.version\u0026gt; \u0026lt;drools.version\u0026gt;8.41.0.Final\u0026lt;/drools.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.drools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;drools-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${drools.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.drools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;drools-compiler\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${drools.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.drools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;drools-decisiontables\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${drools.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.drools\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;drools-mvel\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${drools.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; \u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; 配置类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Configuration public class DroolsConfig { private static final KieServices kieServices = KieServices.Factory.get(); //制定规则文件的路径 private static final String RULES_CUSTOMER_RULES_DRL = \u0026#34;rules/orderScore.drl\u0026#34;; @Bean public KieContainer kieContainer() { //获得Kie容器对象 KieFileSystem kieFileSystem = kieServices.newKieFileSystem(); kieFileSystem.write(ResourceFactory.newClassPathResource(RULES_CUSTOMER_RULES_DRL)); KieBuilder kieBuilder = kieServices.newKieBuilder(kieFileSystem); kieBuilder.buildAll(); KieModule kieModule = kieBuilder.getKieModule(); KieContainer kieContainer = kieServices.newKieContainer(kieModule.getReleaseId()); return kieContainer; } } Order事实类\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 public class Order { private double amout; private double score; public double getAmout() { return amout; } public void setAmout(double amout) { this.amout = amout; } public double getScore() { return score; } public void setScore(double score) { this.score = score; } } orderScore.drl规则文件（resources/rules目录下）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 //订单积分规则 package com.order import com.atguigu.drools.model.Order //规则一：100元以下 不加分 rule \u0026#34;order_rule_1\u0026#34; when $order:Order(amout \u0026lt; 100) then $order.setScore(0); System.out.println(\u0026#34;成功匹配到规则一：100元以下 不加分\u0026#34;); end //规则二：100元 - 500元 加100分 rule \u0026#34;order_rule_2\u0026#34; when $order:Order(amout \u0026gt;= 100 \u0026amp;\u0026amp; amout \u0026lt; 500) then $order.setScore(100); System.out.println(\u0026#34;成功匹配到规则二：100元 - 500元 加100分\u0026#34;); end //规则三：500元 - 1000元 加500分 rule \u0026#34;order_rule_3\u0026#34; when $order:Order(amout \u0026gt;= 500 \u0026amp;\u0026amp; amout \u0026lt; 1000) then $order.setScore(500); System.out.println(\u0026#34;成功匹配到规则三：500元 - 1000元 加500分\u0026#34;); end //规则四：1000元以上 加1000分 rule \u0026#34;order_rule_4\u0026#34; when $order:Order(amout \u0026gt;= 1000) then $order.setScore(1000); System.out.println(\u0026#34;成功匹配到规则四：1000元以上 加1000分\u0026#34;); end 测试\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 @SpringBootTest class DroolsDemosApplicationTests { @Autowired private KieContainer kieContainer; @Test public void test(){ //从Kie容器对象中获取会话对象 KieSession session = kieContainer.newKieSession(); //Fact对象，事实对象 Order order = new Order(); order.setAmout(1300); //将Order对象插入到工作内存中 session.insert(order); //激活规则，由Drools框架自动进行规则匹配，如果规则匹配成功，则执行当前规则 session.fireAllRules(); //关闭会话 session.dispose(); System.out.println(\u0026#34;订单金额：\u0026#34; + order.getAmout() + \u0026#34;，添加积分：\u0026#34; + order.getScore()); } } 三、语法 关键字 描述 package 包名，只限于逻辑上的管理，同一个包名下的查询或者函数可以直接调用 import 用于导入类或者静态方法 global 全局变量 function 自定义函数 query 查询 rule end 规则体 规则体语法结构 1 2 3 4 5 6 7 rule \u0026#34;ruleName\u0026#34; attributes when LHS then RHS end rule：关键字，表示规则开始，参数为规则的唯一名称。\nattributes：规则属性，是rule与when之间的参数，为可选项。\nwhen：关键字，后面跟规则的条件部分。\nLHS(Left Hand Side)：是规则的条件部分的通用名称。它由零个或多个条件元素组成。如果LHS为空，则它将被视为始终为true的条件元素。 （左手边）\nthen：关键字，后面跟规则的结果部分。\nRHS(Right Hand Side)：是规则的后果或行动部分的通用名称。 （右手边）\nend：关键字，表示一个规则结束。\n注释 在drl形式的规则文件中使用注释和Java类中使用注释一致，分为单行注释和多行注释。\n单行注释用\u0026quot;//\u0026ldquo;进行标记，多行注释以\u0026rdquo;/\u0026ldquo;开始，以\u0026rdquo;/\u0026ldquo;结束。如下示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //规则rule1的注释，这是一个单行注释 rule \u0026#34;rule1\u0026#34; when then System.out.println(\u0026#34;rule1触发\u0026#34;); end /* 规则rule2的注释， 这是一个多行注释 */ rule \u0026#34;rule2\u0026#34; when then System.out.println(\u0026#34;rule2触发\u0026#34;); end 前面我们已经知道了Drools中的匹配器可以将Rule Base中的所有规则与Working Memory中的Fact对象进行模式匹配，那么我们就需要在规则体的LHS部分定义规则并进行模式匹配。LHS部分由一个或者多个条件组成，条件又称为pattern。\npattern的语法结构为：绑定变量名:Object(Field约束)\n其中绑定变量名可以省略，通常绑定变量名的命名一般建议以$开始。如果定义了绑定变量名，就可以在规则体的RHS部分使用此绑定变量名来操作相应的Fact对象。Field约束部分是需要返回true或者false的0个或多个表达式。\n例如我们的入门案例中：\n1 2 3 4 5 6 7 8 //规则二：100元 - 500元 加100分 rule \u0026#34;order_rule_2\u0026#34; when $order:Order(amout \u0026gt;= 100 \u0026amp;\u0026amp; amout \u0026lt; 500) then $order.setScore(100); System.out.println(\u0026#34;成功匹配到规则二：100元 - 500元 加100分\u0026#34;); end 通过上面的例子我们可以知道，匹配的条件为：\n1、工作内存中必须存在Order这种类型的Fact对象\u0026mdash;\u0026ndash;类型约束\n2、Fact对象的amout属性值必须大于等于100\u0026mdash;\u0026mdash;属性约束\n3、Fact对象的amout属性值必须小于100\u0026mdash;\u0026mdash;属性约束\n以上条件必须同时满足当前规则才有可能被激活。\n比较操作符 Drools提供的比较操作符，如下表：\n符号 说明 \u0026gt; 大于 \u0026lt; 小于 \u0026gt;= 大于等于 \u0026lt;= 小于等于 == 等于 != 不等于 contains 检查一个Fact对象的某个属性值是否包含一个指定的对象值 not contains 检查一个Fact对象的某个属性值是否不包含一个指定的对象值 memberOf 判断一个Fact对象的某个属性是否在一个或多个集合中 not memberOf 判断一个Fact对象的某个属性是否不在一个或多个集合中 matches 判断一个Fact对象的属性是否与提供的标准的Java正则表达式进行匹配 not matches 判断一个Fact对象的属性是否不与提供的标准的Java正则表达式进行匹配 前6个比较操作符和Java中的完全相同。\nDrools内置方法 规则文件的RHS部分的主要作用是通过插入，删除或修改工作内存中的Fact数据，来达到控制规则引擎执行的目的。Drools提供了一些方法可以用来操作工作内存中的数据，**操作完成后规则引擎会重新进行相关规则的匹配，**原来没有匹配成功的规则在我们修改数据完成后有可能就会匹配成功了。\nupdate方法 update方法的作用是更新工作内存中的数据，并让相关的规则重新匹配。 （要避免死循环）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //规则一：100元以下 不加分 rule \u0026#34;order_rule_1\u0026#34; when $order:Order(amout \u0026lt; 100) then $order.setAmout(150); update($order) //update方法用于更新Fact对象，会导致相关规则重新匹配 System.out.println(\u0026#34;成功匹配到规则一：100元以下 不加分\u0026#34;); end //规则二：100元 - 500元 加100分 rule \u0026#34;order_rule_2\u0026#34; when $order:Order(amout \u0026gt;= 100 \u0026amp;\u0026amp; amout \u0026lt; 500) then $order.setScore(100); System.out.println(\u0026#34;成功匹配到规则二：100元 - 500元 加100分\u0026#34;); end insert方法 insert方法的作用是向工作内存中插入数据，并让相关的规则重新匹配。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 //规则一：100元以下 不加分 rule \u0026#34;order_rule_1\u0026#34; when $order:Order(amout \u0026lt; 100) then Order order = new Order(); order.setAmout(130); insert(order); //insert方法的作用是向工作内存中插入Fact对象，会导致相关规则重新匹配 System.out.println(\u0026#34;成功匹配到规则一：100元以下 不加分\u0026#34;); end //规则二：100元 - 500元 加100分 rule \u0026#34;order_rule_2\u0026#34; when $order:Order(amout \u0026gt;= 100 \u0026amp;\u0026amp; amout \u0026lt; 500) then $order.setScore(100); System.out.println(\u0026#34;成功匹配到规则二：100元 - 500元 加100分\u0026#34;); end retract方法 retract方法的作用是删除工作内存中的数据，并让相关的规则重新匹配。\n1 2 3 4 5 6 7 8 //规则一：100元以下 不加分 rule \u0026#34;order_rule_1\u0026#34; when $order:Order(amout \u0026lt; 100) then retract($order) //retract方法的作用是删除工作内存中的Fact对象，会导致相关规则重新匹配 System.out.println(\u0026#34;成功匹配到规则一：100元以下 不加分\u0026#34;); end 规则属性 attributes 前面我们已经知道了规则体的构成如下：\n1 2 3 4 5 6 7 rule \u0026#34;ruleName\u0026#34; attributes when LHS then RHS end 本章节就是针对规则体的attributes属性部分进行讲解。Drools中提供的属性如下表(部分属性)：\n属性名 说明 salience 指定规则执行优先级 dialect 指定规则使用的语言类型，取值为java和mvel enabled 指定规则是否启用 date-effective 指定规则生效时间 date-expires 指定规则失效时间 activation-group 激活分组，具有相同分组名称的规则只能有一个规则触发 agenda-group 议程分组，只有获取焦点的组中的规则才有可能触发 timer 定时器，指定规则触发的时间 auto-focus 自动获取焦点，一般结合agenda-group一起使用 no-loop 防止死循环 重点说一下我们项目需要使用的属性\nsalience属性 salience属性用于指定规则的执行优先级，取值类型为Integer。数值越大越优先执行。每个规则都有一个默认的执行顺序，如果不设置salience属性，规则体的执行顺序为由上到下。\n可以通过创建规则文件salience.drl来测试salience属性，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 package com.order rule \u0026#34;rule_1\u0026#34; when eval(true) then System.out.println(\u0026#34;规则rule_1触发\u0026#34;); end rule \u0026#34;rule_2\u0026#34; when eval(true) then System.out.println(\u0026#34;规则rule_2触发\u0026#34;); end rule \u0026#34;rule_3\u0026#34; when eval(true) then System.out.println(\u0026#34;规则rule_3触发\u0026#34;); end 通过控制台可以看到，由于以上三个规则没有设置salience属性，所以执行的顺序是按照规则文件中规则的顺序由上到下执行的。接下来我们修改一下文件内容：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 package com.order rule \u0026#34;rule_1\u0026#34; salience 9 when eval(true) then System.out.println(\u0026#34;规则rule_1触发\u0026#34;); end rule \u0026#34;rule_2\u0026#34; salience 10 when eval(true) then System.out.println(\u0026#34;规则rule_2触发\u0026#34;); end rule \u0026#34;rule_3\u0026#34; salience 8 when eval(true) then System.out.println(\u0026#34;规则rule_3触发\u0026#34;); end 通过控制台可以看到，规则文件执行的顺序是按照我们设置的salience值由大到小顺序执行的。\n建议在编写规则时使用salience属性明确指定执行优先级。\nno-loop属性 no-loop属性用于防止死循环，当规则通过update之类的函数修改了Fact对象时，可能使当前规则再次被激活从而导致死循环。取值类型为Boolean，默认值为false，测试步骤如下：\n编写规则文件/resources/rules/activationgroup.drl\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //订单积分规则 package com.order import com.atguigu.drools.model.Order //规则一：100元以下 不加分 rule \u0026#34;order_rule_1\u0026#34; no-loop true //防止陷入死循环 when $order:Order(amout \u0026lt; 100) then $order.setScore(0); update($order) System.out.println(\u0026#34;成功匹配到规则一：100元以下 不加分\u0026#34;); end 通过控制台可以看到，由于我们没有设置no-loop属性的值，所以发生了死循环。接下来设置no-loop的值为true再次测试则不会发生死循环。\nglobal全局变量 global关键字用于在规则文件中定义全局变量，它可以让应用程序的对象在规则文件中能够被访问。可以用来为规则文件提供数据或服务。\n语法结构为：global 对象类型 对象名称\n在使用global定义的全局变量时有两点需要注意：\n1、如果对象类型为包装类型时，在一个规则中改变了global的值，那么只针对当前规则有效，对其他规则中的global不会有影响。可以理解为它是当前规则代码中的global副本，规则内部修改不会影响全局的使用。\n2、如果对象类型为集合类型或JavaBean时，在一个规则中改变了global的值，对java代码和所有规则都有效。\n订单Order：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 package com.atguigu.drools.model; public class Order { private double amout; public double getAmout() { return amout; } public void setAmout(double amout) { this.amout = amout; } } 积分Integral：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 package com.atguigu.drools.model; public class Integral { private double score; public double getScore() { return score; } public void setScore(double score) { this.score = score; } } 规则文件：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //订单积分规则 package com.order import com.atguigu.drools.model.Order global com.atguigu.drools.model.Integral integral; //规则一：100元以下 不加分 rule \u0026#34;order_rule_1\u0026#34; no-loop true //防止陷入死循环 when $order:Order(amout \u0026lt; 100) then integral.setScore(10); update($order) System.out.println(\u0026#34;成功匹配到规则一：100元以下 不加分\u0026#34;); end 测试：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 @Test public void test1(){ //从Kie容器对象中获取会话对象 KieSession session = kieContainer.newKieSession(); //Fact对象，事实对象 Order order = new Order(); order.setAmout(30); //全局变量 Integral integral = new Integral(); session.setGlobal(\u0026#34;integral\u0026#34;, integral); //将Order对象插入到工作内存中 session.insert(order); //激活规则，由Drools框架自动进行规则匹配，如果规则匹配成功，则执行当前规则 session.fireAllRules(); //关闭会话 session.dispose(); System.out.println(\u0026#34;订单金额：\u0026#34; + order.getAmout()); System.out.println(\u0026#34;添加积分：\u0026#34; + integral.getScore()); } ","date":"2025-09-26T00:03:35+08:00","image":"https://zell.zone/p/%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E/img/1_hu_8098c89de2281b3e.jpg","permalink":"https://zell.zone/p/%E8%A7%84%E5%88%99%E5%BC%95%E6%93%8E/","title":"规则引擎"},{"content":"正在做一个mq发送的业务，在微服务模块中，如果每个模块都要单独去引入MQ并且实现各种配置，感觉这个操作太乱了。突发奇想自己试着实现一个统一的模块来实现管理，接下来就是上手时间。\n代码结构\n我以整合RabbitMQ类捋一下我的思路 一、定义一个消息体接口，用于统一的发送接口的参数 1 2 3 public interface MessageModel { } 二、定义一个发送消息接口，用于多态实现统一的发送接口 1 2 3 4 5 public interface MqSendModel { boolean sendMessage(MessageModel messageModel); } 接下来就是整合RabbitMQ的具体操作了 三、加入依赖 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-amqp\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.alibaba.fastjson2\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;fastjson2\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- 缓存服务 --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.share\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;share-common-redis\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; 四、连接信息类RabbitMqProperties 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @Data @ConditionalOnProperty(name = \u0026#34;share.rabbit.active\u0026#34;, havingValue = \u0026#34;true\u0026#34;) @ConfigurationProperties(prefix = \u0026#34;spring.rabbitmq\u0026#34;) @Component public class RabbitMqProperties { private String host; private int port; private String username; private String password; private String virtualHost; private int connectionTimeout =5000; private int requestedHeartbeat =60; private String publisherConfirmType; private Boolean publisherReturns; } 使用了@ConditionalOnProperty 和 @ConfigurationProperties来实现当配置了share.rabbit.active = true 时，该配置类才会注册\n五、连接配置类RabbitConfig 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 package com.xxx.mq.rabbit.config; import com.alibaba.fastjson2.JSON; import com.xxx.mq.rabbit.dto.RabbitCorrelationData; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.core.Message; import org.springframework.amqp.core.MessageBuilder; import org.springframework.amqp.core.MessageProperties; import org.springframework.amqp.rabbit.connection.CachingConnectionFactory; import org.springframework.amqp.rabbit.connection.CorrelationData; import org.springframework.amqp.rabbit.core.RabbitAdmin; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.amqp.support.converter.Jackson2JsonMessageConverter; import org.springframework.amqp.support.converter.MessageConverter; import org.springframework.beans.factory.annotation.Autowired; import org.springframework.boot.autoconfigure.AutoConfigureAfter; import org.springframework.boot.autoconfigure.condition.ConditionalOnBean; import org.springframework.context.ApplicationContext; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.context.annotation.DependsOn; import org.springframework.data.redis.core.RedisTemplate; import java.nio.charset.StandardCharsets; import java.util.Objects; import java.util.concurrent.TimeUnit; @ConditionalOnBean(RabbitMqProperties.class) // 使用类字面量 @AutoConfigureAfter(RabbitMqProperties.class) @Configuration @Slf4j public class RabbitConfig { @Autowired private RabbitMqProperties rabbitMqProperties; @Autowired private RedisTemplate redisTemplate; @Bean public CachingConnectionFactory connectionFactory() { CachingConnectionFactory connectionFactory = new CachingConnectionFactory(); connectionFactory.setHost(rabbitMqProperties.getHost()); connectionFactory.setPort(rabbitMqProperties.getPort()); connectionFactory.setUsername(rabbitMqProperties.getUsername()); connectionFactory.setPassword(rabbitMqProperties.getPassword()); connectionFactory.setVirtualHost(rabbitMqProperties.getVirtualHost()); String publisherConfirmType = rabbitMqProperties.getPublisherConfirmType(); connectionFactory.setPublisherConfirmType(CachingConnectionFactory.ConfirmType.valueOf(publisherConfirmType)); connectionFactory.setConnectionTimeout(rabbitMqProperties.getConnectionTimeout()); connectionFactory.setRequestedHeartBeat(rabbitMqProperties.getRequestedHeartbeat()); connectionFactory.setPublisherReturns(rabbitMqProperties.getPublisherReturns()); log.info(\u0026#34;自定义RabbitMQ连接工厂已创建，连接至: {}:{}\u0026#34;, rabbitMqProperties.getHost(), rabbitMqProperties.getPort()); return connectionFactory; } @Bean public RabbitTemplate rabbitTemplate(CachingConnectionFactory connectionFactory) { RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); // 设置消息转换器 rabbitTemplate.setMessageConverter(jsonMessageConverter()); // 开启返回模式 rabbitTemplate.setMandatory(true); // 确认回调 rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -\u0026gt; { if (!(correlationData instanceof RabbitCorrelationData rabbitCorrelationData)) { log.warn(\u0026#34;非RabbitCorrelationData类型，忽略确认回调: {}\u0026#34;, correlationData); return; } if (ack) { log.info(\u0026#34;消息[{}]发送成功（交换机: {}）\u0026#34;, rabbitCorrelationData.getId(), rabbitCorrelationData.getExchangeName()); // 成功后删除Redis备份（避免冗余） redisTemplate.delete(rabbitCorrelationData.getId()); } else { log.error(\u0026#34;消息[{}]发送失败（交换机: {}），原因: {}\u0026#34;, rabbitCorrelationData.getId(), rabbitCorrelationData.getExchangeName(), cause); retrySendMsg(rabbitCorrelationData, rabbitTemplate); // 投递失败重试 } }); // 返回回调 rabbitTemplate.setReturnsCallback(returned -\u0026gt; { Message message = returned.getMessage(); if (message == null) { log.error(\u0026#34;路由失败的消息为空，忽略处理\u0026#34;); return; } // 提取消息元数据（防御空指针） MessageProperties props = message.getMessageProperties(); String correlationId = props.getHeader(\u0026#34;correlation_id\u0026#34;); Boolean isDelay = props.getHeader(\u0026#34;is_delay\u0026#34;); // 关键：延迟消息的NO_ROUTE是正常暂存，无需重发 if (isDelay != null \u0026amp;\u0026amp; isDelay) { log.info(\u0026#34;延迟消息[{}]暂存中，忽略NO_ROUTE（交换机: {}, 路由键: {}）\u0026#34;, correlationId, returned.getExchange(), returned.getRoutingKey()); return; } // 非延迟消息的路由失败：触发重发 log.error(\u0026#34;非延迟消息路由失败！correlationId: {}, replyCode: {}, replyText: {}, 交换机/路由键: {}/{}\u0026#34;, correlationId, returned.getReplyCode(), returned.getReplyText(), returned.getExchange(), returned.getRoutingKey()); // 构建CorrelationData并重试 if (correlationId != null) { String correlationDataStr = (String) redisTemplate.opsForValue().get(correlationId); if (correlationDataStr != null) { RabbitCorrelationData rabbitCorrelationData = JSON.parseObject(correlationDataStr, RabbitCorrelationData.class); retrySendMsg(rabbitCorrelationData, rabbitTemplate); } else { log.error(\u0026#34;消息[{}]的元数据在Redis中不存在，无法重试\u0026#34;, correlationId); } } }); return rabbitTemplate; } @Bean public MessageConverter jsonMessageConverter() { return new Jackson2JsonMessageConverter(); } @Bean public RabbitAdmin amqpAdmin(CachingConnectionFactory connectionFactory) { return new RabbitAdmin(connectionFactory); } /** * 消息重新发送 * * @param correlationData */ private void retrySendMsg(CorrelationData correlationData, RabbitTemplate rabbitTemplate) { //获取相关数据 RabbitCorrelationData rabbitCorrelationData = (RabbitCorrelationData) correlationData; //获取redis中存放重试次数 //先重发，在写会到redis中次数 int retryCount = rabbitCorrelationData.getRetryCount(); if (retryCount \u0026gt;= 3) { //超过最大重试次数 log.error(\u0026#34;生产者超过最大重试次数，将失败的消息存入数据库用人工处理；给管理员发送邮件；给管理员发送短信；\u0026#34;); return; } //重发消息 sendMessage(rabbitCorrelationData, rabbitTemplate); //重发次数+1 retryCount += 1; rabbitCorrelationData.setRetryCount(retryCount); redisTemplate.opsForValue().set(rabbitCorrelationData.getId(), JSON.toJSONString(rabbitCorrelationData), 10, TimeUnit.MINUTES); log.info(\u0026#34;进行消息重发！\u0026#34;); } private void sendMessage(RabbitCorrelationData rabbitCorrelationData, RabbitTemplate rabbitTemplate) { Objects.requireNonNull(rabbitCorrelationData.getExchangeName(), \u0026#34;交换机名称不能为空\u0026#34;); Objects.requireNonNull(rabbitCorrelationData.getRoutingKey(), \u0026#34;路由键不能为空\u0026#34;); Objects.requireNonNull(rabbitCorrelationData.getMessage(), \u0026#34;消息体不能为空\u0026#34;); byte[] messageBody; if (rabbitCorrelationData.getMessage() instanceof String) { messageBody = JSON.toJSONString(rabbitCorrelationData.getMessage()).getBytes(StandardCharsets.UTF_8); } else { messageBody = JSON.toJSONString(rabbitCorrelationData).getBytes(StandardCharsets.UTF_8); } // .withBody(messageBody) 部分是 真正传递到消费者的 // send参数中的rabbitCorrelationData只会在回调中使用，不会到消费者 Message message = MessageBuilder .withBody(messageBody).setContentType(MessageProperties.CONTENT_TYPE_JSON).setContentEncoding(StandardCharsets.UTF_8.name()) .setHeader(\u0026#34;correlation_id\u0026#34;, rabbitCorrelationData.getId()) .setHeader(\u0026#34;retry_count\u0026#34;, rabbitCorrelationData.getRetryCount()) .setHeader(\u0026#34;is_delay\u0026#34;, rabbitCorrelationData.isDelay()) .build(); if (rabbitCorrelationData.getDelayTime() != null) { message.getMessageProperties() .setDelay(rabbitCorrelationData.getDelayTime()); } rabbitTemplate.send(rabbitCorrelationData.getExchangeName(), rabbitCorrelationData.getRoutingKey(), message, rabbitCorrelationData); } } 这部分遇到了几个问题，在这里总结一下 问题一：加载时机的问题 问题原因：在上面配置信息类中使用的时@Component注解将配置信息注入到Spring容器中，但是这里是配置类使用的注解@Configuration在正常不做干扰的情况下执行顺序是比@Component早的。而我为了防止在获取配置属性空指针，加上了@ConditionalOnBean(RabbitMqProperties.class)注解，只有当Spring容器中存在RabbitMqProperties对象时才会构建当前类，那么问题就出现了，我都比你先加载了，我还能要求你存在吗，这肯定不符合逻辑。虽然一开始我加上了@DependsOn(\u0026quot;rabbitMqProperties\u0026quot;)，但是这个注解只针对控制普通 bean 的初始化顺序，和@Configuration不搭。\n解决办法：使用@AutoConfigureAfter(RabbitMqProperties.class)注解。\n问题二：延时消息的发送一定会进入返回回调setReturnsCallback中，判断有问题导致一直在重发 问题原因：这里讲一下消息发送的过程\n普通消息：客户端发送消息 ——\u0026gt; 交换机（根据路由匹配队列）——\u0026gt; 队列\n延时消息：客户端发送消息 ——\u0026gt; 交换机不会马上路由匹配队列，而是暂存消息，等到设置的时间到了才会路由匹配队列——\u0026gt; 队列\n会导致进入setReturnsCallback的原因：\n对于普通交换机（如 direct/topic）：消息到达后立即匹配路由键，若有队列绑定则路由，无则触发 NO_ROUTE。 对于延迟交换机：消息到达后不立即路由，而是暂存，因此 RabbitMQ 会判定 “当前无队列匹配”，即使后续延迟到期会路由，也会在 消息到达时即时触发 NO_ROUTE，进而触发 ReturnsCallback。 所以在进入回调后需要判断是否是由延迟消息导致，如果是就不能进行重发了。\n六、消息实现类RabbitCorrelationData 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 @Data public class RabbitCorrelationData extends CorrelationData implements MessageModel { //消息体 private Object message; //交换机名称 private String exchangeName; //路由键 private String routingKey; //重试次数 private int retryCount = 0; //是否延迟消息 private boolean isDelay ; //延迟时长 private Integer delayTime ; //交换机类型 private MqConstants.ExchangeType exchangeType = MqConstants.ExchangeType.DIRECT_EXCHANGE; } public interface MqConstants { @Getter @AllArgsConstructor enum ExchangeType { /** * 精确路由键匹配 一对一通信、精确路由 */ DIRECT_EXCHANGE(\u0026#34;direct\u0026#34;), /** * 通配符路由键匹配 按主题 / 类别路由（如日志） */ TOPIC_EXCHANGE(\u0026#34;topic\u0026#34;), /** * （广播）广播通知、多队列同步 */ FANOUT_EXCHANGE(\u0026#34;fanout\u0026#34;), /** * 消息头信息匹配 复杂多条件路由（较少用） */ HEADERS_EXCHANGE(\u0026#34;headers\u0026#34;), /** * 延迟时间 + 基础路由规则中延迟任务、定时投递 */ // DELAY_EXCHANGE(\u0026#34;delay\u0026#34;), ; private String name; } } 扩展：\n交换机类型 匹配规则 效率 通信 DirectExchange 精确路由键匹配 低 一对一通信、精确路由 TopicExchange 通配符路由键匹配 中 按主题 / 类别路由（如日志） FanoutExchange 无（广播） 低 广播通知、多队列同步 HeadersExchange 消息头信息匹配 高 复杂多条件路由（较少用） DelayExchange 延迟时间 + 基础路由规则 中 延迟任务、定时投递 七、消息发送类RabbitMqService 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 package com.xxx.mq.rabbit.service; import com.alibaba.fastjson2.JSON; import com.baomidou.mybatisplus.core.toolkit.StringPool; import com.xxx.common.core.exception.ServiceException; import com.xxx.mq.model.MessageModel; import com.xxx.mq.model.MqSendModel; import com.xxx.mq.rabbit.constants.MqConstants; import com.xxx.mq.rabbit.dto.RabbitCorrelationData; import lombok.AllArgsConstructor; import lombok.extern.slf4j.Slf4j; import org.springframework.amqp.AmqpException; import org.springframework.amqp.core.*; import org.springframework.amqp.rabbit.core.RabbitAdmin; import org.springframework.amqp.rabbit.core.RabbitTemplate; import org.springframework.boot.autoconfigure.condition.ConditionalOnBean; import org.springframework.data.redis.core.RedisTemplate; import org.springframework.stereotype.Component; import java.io.IOException; import java.nio.charset.StandardCharsets; import java.util.HashMap; import java.util.Map; import java.util.Properties; import java.util.concurrent.TimeUnit; @Component @ConditionalOnBean(name = \u0026#34;rabbitTemplate\u0026#34;) @AllArgsConstructor @Slf4j public class RabbitMqService implements MqSendModel { private final RabbitTemplate rabbitTemplate; private final RedisTemplate redisTemplate; private final RabbitAdmin rabbitAdmin; @Override public boolean sendMessage(MessageModel messageModel, Integer delaySeconds) { if (!(messageModel instanceof RabbitCorrelationData)) { throw new IllegalArgumentException(\u0026#34;RabbitMQ发送失败，期望参数类型为：RabbitCorrelationData ， 实际参数类型为：\u0026#34; + messageModel.getClass()); } RabbitCorrelationData rabbitCorrelationData = (RabbitCorrelationData) messageModel; rabbitCorrelationData.setDelay(delaySeconds != null); rabbitCorrelationData.setDelayTime(delaySeconds); //redis 存储消息元数据 int time = delaySeconds == null ? 0 : delaySeconds; redisTemplate.opsForValue().set(rabbitCorrelationData.getId(), JSON.toJSONString(rabbitCorrelationData), 10 + ((time / 60) \u0026gt; 0 ? time / 60 : 1), TimeUnit.MINUTES); //发送MQ消息 sendMessage(rabbitCorrelationData, delaySeconds); return true; } private void sendMessage(RabbitCorrelationData rabbitCorrelationData, Integer delaySeconds) { byte[] messageBody = null; if (rabbitCorrelationData.getMessage() instanceof String) { messageBody = JSON.toJSONString(rabbitCorrelationData.getMessage()).getBytes(StandardCharsets.UTF_8); } else { messageBody = JSON.toJSONString(rabbitCorrelationData).getBytes(StandardCharsets.UTF_8); } // .withBody(messageBody) 部分是 真正传递到消费者的 // send参数中的rabbitCorrelationData只会在回调中使用，不会到消费者 Message message = MessageBuilder .withBody(messageBody).setContentType(MessageProperties.CONTENT_TYPE_TEXT_PLAIN) .setHeader(\u0026#34;correlation_id\u0026#34;, rabbitCorrelationData.getId()) .setHeader(\u0026#34;retry_count\u0026#34;, rabbitCorrelationData.getRetryCount()) .setHeader(\u0026#34;is_delay\u0026#34;, rabbitCorrelationData.isDelay()) .build(); if (delaySeconds != null) { message.getMessageProperties() .setDelay(delaySeconds * 1000); } exchangeAndQueue(rabbitCorrelationData, delaySeconds != null); rabbitTemplate.send(rabbitCorrelationData.getExchangeName(), rabbitCorrelationData.getRoutingKey(), message, rabbitCorrelationData); } private void exchangeAndQueue(RabbitCorrelationData rabbitCorrelationData, boolean isDelay) { Exchange exchange = null; // 1. 处理交换机 //交换机是否存在 boolean exchangeExists = isExchangeExists(rabbitCorrelationData.getExchangeName()); if (!exchangeExists) { //是否创建队列 exchange = createExchange(rabbitCorrelationData.getExchangeName(), rabbitCorrelationData.getExchangeType(), isDelay); rabbitAdmin.declareExchange(exchange); log.info(\u0026#34;完成创建交换机：{} 类型 ：{}\u0026#34;, exchange.getName(), exchange.getType()); } // 2. 处理队列 String queueName = generateQueueName(rabbitCorrelationData.getExchangeName(), rabbitCorrelationData.getRoutingKey()); boolean queueExists = isQueueExists(queueName); Queue queue = null; if (!queueExists) { queue = new Queue(queueName, true, false, false); rabbitAdmin.declareQueue(queue); log.info(\u0026#34;完成创建队列：{}\u0026#34;, queue.getName()); } Binding binding = null; // 3. 确保绑定存在（直接声明，利用异常处理） ensureBindingExists(rabbitCorrelationData.getExchangeName(), queueName, rabbitCorrelationData.getRoutingKey()); } private void ensureBindingExists(String exchangeName, String queueName, String routingKey) { try { Binding binding = new Binding(queueName, Binding.DestinationType.QUEUE, exchangeName, routingKey, null); rabbitAdmin.declareBinding(binding); log.info(\u0026#34;绑定已就绪: {}-\u0026gt;{}[{}]\u0026#34;, exchangeName, queueName, routingKey); } catch (Exception e) { // 绑定已存在的异常可以安全忽略 if (e.getMessage().contains(\u0026#34;already exists\u0026#34;) || (e.getCause() != null \u0026amp;\u0026amp; e.getCause().getMessage().contains(\u0026#34;no exchange\u0026#34;))) { log.debug(\u0026#34;绑定已存在: {}-\u0026gt;{}[{}]\u0026#34;, exchangeName, queueName, routingKey); } else { log.warn(\u0026#34;绑定声明异常（可能已存在）: {}-\u0026gt;{}[{}]\u0026#34;, exchangeName, queueName, routingKey, e); } } } private Exchange createExchange(String exchangeName, MqConstants.ExchangeType exchangeType, Boolean isDelay) { if (isDelay) { Map\u0026lt;String, Object\u0026gt; args = new HashMap\u0026lt;\u0026gt;(); args.put(\u0026#34;x-delayed-type\u0026#34;, exchangeType.getName()); // 指定交换机类型（如 direct、topic 等） return new CustomExchange(exchangeName, \u0026#34;x-delayed-message\u0026#34;, true, false, args); } switch (exchangeType) { case FANOUT_EXCHANGE: return new FanoutExchange(exchangeName, true, false); case DIRECT_EXCHANGE: return new DirectExchange(exchangeName, true, false); case TOPIC_EXCHANGE: return new TopicExchange(exchangeName, true, false); case HEADERS_EXCHANGE: // return new HeadersExchange(); throw new ServiceException(\u0026#34;暂不支持该类型：\u0026#34; + MqConstants.ExchangeType.HEADERS_EXCHANGE.getName() + \u0026#34;交换机创建！\u0026#34;); default: throw new ServiceException(\u0026#34;暂不支持该类型：\u0026#34; + MqConstants.ExchangeType.HEADERS_EXCHANGE.getName() + \u0026#34;交换机创建！\u0026#34;); } } public String generateQueueName(String exchangeName, String routingKey) { return exchangeName + StringPool.DOT + routingKey + StringPool.DOT + \u0026#34;queue\u0026#34;; } private boolean isQueueExists(String queueName) { Properties queueProperties = rabbitAdmin.getQueueProperties(queueName); return queueProperties != null; } private boolean isExchangeExists(String exchangeName) { try { // 关键：通过 RabbitTemplate.execute() 获取 Spring 管理的 Channel // 被动声明交换机：仅查询，不创建 // 无异常 → 交换机存在 // 捕获 Channel 操作中的异常（如 404） // 交换机不存在 // 其他异常向上抛出（被外层 try-catch 捕获） return Boolean.TRUE.equals(rabbitTemplate.execute(channel -\u0026gt; { try { // 被动声明交换机：仅查询，不创建 channel.exchangeDeclarePassive(exchangeName); // 无异常 → 交换机存在 return true; } catch (IOException e) { // 捕获 Channel 操作中的异常（如 404） if (e.getCause().getMessage().contains(\u0026#34;404\u0026#34;)) { return false; // 交换机不存在 } // 其他异常向上抛出（被外层 try-catch 捕获） throw e; } })); } catch (Exception e) { // 处理整体异常（如连接超时、权限不足） if (e.getCause() instanceof IOException \u0026amp;\u0026amp; e.getCause().getMessage().contains(\u0026#34;404\u0026#34;)) { return false; } throw new AmqpException(\u0026#34;查询交换机失败：\u0026#34; + e.getMessage(), e); } } } 在消息发送时判断了交换机、队列、路由是否存在，不存在则创建。\n八、最后，为了在其他模块引入该模块这些类能正确被Spring扫描到，需要在org.springframework.boot.autoconfigure.AutoConfiguration.imports中加入配置 1 2 3 com.xxx.mq.rabbit.config.RabbitMqProperties com.xxx.mq.rabbit.config.RabbitConfig com.xxx.mq.rabbit.service.RabbitMqService 九、测试 在业务模块中引入该模块包依赖\n配置相关信息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 spring: rabbitmq: host: localhost port: 5672 username: guest password: guest virtual-host: /share publisher-confirm-type: CORRELATED publisher-returns: true listener: simple: cknowledge-mode: manual #默认情况下消息消费者是自动确认消息的，如果要手动确认消息则需要修改确认模式为manual prefetch: 1 # 消费者每次从队列获取的消息数量。此属性当不设置时为：轮询分发，设置为1为：公平分发 # 使用rabbitMQ share: rabbit: active: true 发送消息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @RestController public class MqController { @Autowired private RabbitMqService rabbitMqService; @Operation(summary = \u0026#34;发送延迟消息\u0026#34;) @GetMapping(\u0026#34;/sendDelay\u0026#34;) public AjaxResult sendDelay(String msg) { RabbitCorrelationData data = new RabbitCorrelationData(); data.setMessage(msg); data.setExchangeName(\u0026#34;test-delay-exchange\u0026#34;); data.setRoutingKey(\u0026#34;test\u0026#34;); data.setId(UUID.randomUUID().toString()); rabbitMqService.sendMessage( data, 15); return success(); } @Operation(summary = \u0026#34;发送确认消息\u0026#34;) @GetMapping(\u0026#34;/send\u0026#34;) public AjaxResult send(String msg) { RabbitCorrelationData data = new RabbitCorrelationData(); data.setMessage(msg); data.setExchangeName(\u0026#34;test-exchange\u0026#34;); data.setRoutingKey(\u0026#34;test\u0026#34;); data.setId(UUID.randomUUID().toString()); rabbitMqService.sendMessage( data, null); return success(); } } 监听消息\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 @Component @Slf4j public class Test { @Autowired private RedisTemplate redisTemplate; @RabbitListener(queues = \u0026#34;test-delay-exchange.test.queue\u0026#34;) public void testListener(String msg, Message message, Channel channel) throws IOException { //接收消息，消费者端判断是否需要做幂等性处理 //如果业务保证幂等性，基于redis setnx保证 String key = \u0026#34;mq:\u0026#34; + msg; Boolean flag = redisTemplate.opsForValue().setIfAbsent(key, \u0026#34;\u0026#34;, 200, TimeUnit.SECONDS); if (!flag) { //说明该业务数据已经被执行 channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); return; } // 执行业务 // TODO log.info(\u0026#34;接受到消息：{}，主体为{},--{}\u0026#34; , msg , message.toString(),message.getMessageProperties().getDeliveryTag()); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); } @RabbitListener(queues = \u0026#34;test-exchange.test.queue\u0026#34;) public void testListener(String msg, Message message, Channel channel) throws IOException { //接收消息，消费者端判断是否需要做幂等性处理 //如果业务保证幂等性，基于redis setnx保证 String key = \u0026#34;mq:\u0026#34; + msg; Boolean flag = redisTemplate.opsForValue().setIfAbsent(key, \u0026#34;\u0026#34;, 200, TimeUnit.SECONDS); if (!flag) { //说明该业务数据已经被执行 channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); return; } // 执行业务 // TODO log.info(\u0026#34;接受到消息：{}，主体为{},--{}\u0026#34; , msg , message.toString(),message.getMessageProperties().getDeliveryTag()); channel.basicAck(message.getMessageProperties().getDeliveryTag(), false); } } 打印延迟消息发送日志，23:01:23.981发送，23:01:38.984接受成功，证明成功了\n1 2 3 4 5 6 23:01:23.973 [http-nio-9212-exec-1] INFO c.s.m.r.s.RabbitMqService - [ensureBindingExists,114] - 绑定已就绪: test-exchange-\u0026gt;test-exchange.test.queue[test] 23:01:23.980 [connectionFactory1] INFO c.s.m.r.c.RabbitConfig - [lambda$rabbitTemplate$1,96] - 延迟消息[3343986a-662e-41ae-8a0f-9dbbcc2793d2]暂存中，忽略NO_ROUTE（交换机: test-exchange, 路由键: test） 23:01:23.981 [connectionFactory1] INFO c.s.m.r.c.RabbitConfig - [lambda$rabbitTemplate$0,72] - 消息[3343986a-662e-41ae-8a0f-9dbbcc2793d2]发送成功（交换机: test-exchange） 23:01:38.984 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] WARN o.s.a.s.c.Jackson2JsonMessageConverter - [fromMessage,325] - Could not convert incoming message with content-type [text/plain], \u0026#39;json\u0026#39; keyword missing. 23:01:38.997 [org.springframework.amqp.rabbit.RabbitListenerEndpointContainer#0-1] INFO c.s.o.r.l.Test - [testListener,37] - 接受到消息：\u0026#34;正在进行测试延迟消息的发送32\u0026#34;，主体为(Body:\u0026#39;\u0026#34;正在进行测试延迟消息的发送32\u0026#34;\u0026#39; MessageProperties [headers={spring_listener_return_correlation=bf33998d-639a-450e-a258-d59de7c19e6c, spring_returned_message_correlation=3343986a-662e-41ae-8a0f-9dbbcc2793d2, retry_count=0, correlation_id=3343986a-662e-41ae-8a0f-9dbbcc2793d2, is_delay=true}, contentType=text/plain, contentLength=0, receivedDeliveryMode=PERSISTENT, priority=0, redelivered=false, receivedExchange=test-exchange, receivedRoutingKey=test, receivedDelay=15000, deliveryTag=1, consumerTag=amq.ctag--7dyhSB05z_2PmUs7A6hbw, consumerQueue=test-exchange.test.queue]),--1 23:01:39.001 [AMQP Connection 192.168.23.100:5672] ERROR o.s.a.r.c.CachingConnectionFactory - [log,742] - Shutdown Signal: channel error; protocol method: #method\u0026lt;channel.close\u0026gt;(reply-code=406, reply-text=PRECONDITION_FAILED - unknown delivery tag 1, class-id=60, method-id=80) ","date":"2025-09-21T22:08:33+08:00","image":"https://zell.zone/p/%E6%95%B4%E5%90%88mq%E7%9A%84%E5%85%AC%E5%85%B1%E6%A8%A1%E5%9D%97/img/1_hu_51171c6e0116b335.jpg","permalink":"https://zell.zone/p/%E6%95%B4%E5%90%88mq%E7%9A%84%E5%85%AC%E5%85%B1%E6%A8%A1%E5%9D%97/","title":"整合MQ的公共模块"},{"content":"mp 插件处理 首先自定义一个接口QueryInterceptor：用于自定义过滤器的规范\n1 2 3 4 5 6 7 8 9 public interface QueryInterceptor extends Ordered { void intercept(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql); @Override default int getOrder() { return 2147483647; } } 实现Ordered接口是为了排序，给过滤器排上先后顺序。\nPaginationInnerInterceptor是mybatisPlus的过滤器的主要类\n定义一个类集成PaginationInnerInterceptor类，重写willDoQuery方法，加上我们自己的过滤器执行逻辑.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 public class MyPaginationInnerInterceptor extends PaginationInnerInterceptor { private QueryInterceptor[] queryInterceptors; @Override public boolean willDoQuery(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) throws SQLException { try { //执行自己的逻辑 QueryInterceptorExecutor.executor(this.queryInterceptors,executor,ms,parameter,rowBounds,resultHandler,boundSql); return super.willDoQuery(executor, ms, parameter, rowBounds, resultHandler, boundSql); } catch (Throwable e) { throw e; } } public void setQueryInterceptors(QueryInterceptor[] queryInterceptors) { this.queryInterceptors = queryInterceptors; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 public class QueryInterceptorExecutor { public static void executor(QueryInterceptor[] queryInterceptors, Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) { if (queryInterceptors != null \u0026amp;\u0026amp; queryInterceptors.length != 0) { QueryInterceptor[] var1 = queryInterceptors; int length = var1.length; for (int i = 0; i \u0026lt; length; i++) { QueryInterceptor queryInterceptor = var1[i]; queryInterceptor.intercept(executor,ms,parameter,rowBounds,resultHandler,boundSql); } } } } 实现自己的过滤器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @Component public class MyQueryInterceptor implements QueryInterceptor { private ConcurrentMap\u0026lt;String, Object\u0026gt; concurrentMap = new ConcurrentHashMap(8); @Override public void intercept(Executor executor, MappedStatement ms, Object parameter, RowBounds rowBounds, ResultHandler resultHandler, BoundSql boundSql) { if (ms.getSqlCommandType() == SqlCommandType.SELECT \u0026amp;\u0026amp; ms.getStatementType() == StatementType.CALLABLE) { //原sql String originalSql = boundSql.getSql(); //业务逻辑，对原sql继续加工 //..... //执行sql PluginUtils.MPBoundSql mpBoundSql = PluginUtils.mpBoundSql(boundSql); mpBoundSql.sql(originalSql); } } } mybatis-plus的配置\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Configuration public class MybatisPlusConfig { @Bean public MybatisPlusInterceptor mybatisPlusInterceptor(ObjectProvider\u0026lt;QueryInterceptor[]\u0026gt; provider){ MybatisPlusInterceptor mybatisPlusInterceptor = new MybatisPlusInterceptor(); MyPaginationInnerInterceptor myPaginationInnerInterceptor = new MyPaginationInnerInterceptor(); QueryInterceptor[] queryInterceptors = provider.getIfAvailable(); if (queryInterceptors != null){ AnnotationAwareOrderComparator.sort(queryInterceptors); myPaginationInnerInterceptor.setQueryInterceptors(queryInterceptors); } mybatisPlusInterceptor.addInnerInterceptor(myPaginationInnerInterceptor); return mybatisPlusInterceptor; } } ","date":"2025-09-20T00:00:05Z","image":"https://zell.zone/p/mybatis-plus%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8F%92%E4%BB%B6/img/1_hu_9e4e9426a2fab57b.jpg","permalink":"https://zell.zone/p/mybatis-plus%E7%9A%84%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8F%92%E4%BB%B6/","title":"Mybatis Plus的自定义插件"},{"content":"步骤1：创建 Interceptor 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 @Component @Slf4j public class InternalRequestInterceptor implements RequestInterceptor { @Value(\u0026#34;${spring.application.name:unknown}\u0026#34;) private String serviceName; @Override public void apply(RequestTemplate template) { log.debug(\u0026#34;Applying internal request headers for: {}\u0026#34;, template.url()); template.header(\u0026#34;X-Internal-Request\u0026#34;, \u0026#34;true\u0026#34;); template.header(\u0026#34;X-Service-Name\u0026#34;, serviceName); template.header(\u0026#34;X-Request-ID\u0026#34;, UUID.randomUUID().toString()); template.header(\u0026#34;X-Timestamp\u0026#34;, String.valueOf(System.currentTimeMillis())); } } 步骤2：确保 Spring 配置正确 1 2 3 4 5 6 7 @SpringBootApplication @EnableFeignClients // 这个注解必须要有！ public class OrderServiceApplication { public static void main(String[] args) { SpringApplication.run(OrderServiceApplication.class, args); } } 步骤3：验证配置 创建测试类验证：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 @SpringBootTest public class FeignInterceptorTest { @Autowired private UserServiceClient userServiceClient; @MockBean private UserServiceClient mockUserServiceClient; // 用于模拟 @Test public void testInterceptorRegistration() { // 检查Interceptor是否被Spring管理 Map\u0026lt;String, RequestInterceptor\u0026gt; interceptors = applicationContext.getBeansOfType(RequestInterceptor.class); assertThat(interceptors).isNotEmpty(); assertThat(interceptors.values()) .anyMatch(interceptor -\u0026gt; interceptor instanceof InternalRequestInterceptor); } } 高级配置 - 使用自定义 Feign Builder 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Configuration public class CustomFeignConfig { @Autowired private List\u0026lt;RequestInterceptor\u0026gt; requestInterceptors; @Bean public Feign.Builder feignBuilder() { return Feign.builder() .requestInterceptors(requestInterceptors) .logger(new Slf4jLogger()) .logLevel(Logger.Level.FULL); } } 如果该拦截器和配置类是作为核心包被其他模块引入的 在核心包创建resources/META-INF/spring.factories\n1 2 3 4 5 6 7 # META-INF/spring.factories org.springframework.boot.autoconfigure.EnableAutoConfiguration=\\ com.yourcompany.common.config.CommonFeignConfig,\\ com.yourcompany.common.interceptor.CommonRequestInterceptor org.springframework.cloud.openfeign.FeignClientSpecification=\\ com.yourcompany.common.config.CommonFeignConfig 或者说spring为3.+版本 ， 使用resources/META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports文件\n1 2 3 com.yourcompany.common.config.CommonFeignConfig com.yourcompany.common.interceptor.CommonRequestInterceptor com.yourcompany.common.config.CommonFeignConfig 检查 Interceptor 是否生效的调试方法 方法1：查看启动日志 在应用启动时，查看是否有这样的日志：\n1 2 Registered Feign client [UserServiceClient] Found RequestInterceptor [internalRequestInterceptor] 方法2：启用调试日志 1 2 3 4 logging: level: org.springframework.cloud.openfeign: DEBUG feign: DEBUG 方法3：添加调试代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 @Component public class DebugInterceptor implements RequestInterceptor { @PostConstruct public void init() { System.out.println(\u0026#34;Feign Interceptor initialized and registered!\u0026#34;); } @Override public void apply(RequestTemplate template) { System.out.println(\u0026#34;Interceptor applied to: \u0026#34; + template.url()); System.out.println(\u0026#34;Headers: \u0026#34; + template.headers()); } } ","date":"2025-09-20T00:00:01Z","image":"https://zell.zone/p/%E7%BB%99feign%E6%8E%A5%E5%8F%A3%E8%AE%BE%E7%BD%AE%E6%8B%A6%E6%88%AA%E5%99%A8/img/1_hu_9e4e9426a2fab57b.jpg","permalink":"https://zell.zone/p/%E7%BB%99feign%E6%8E%A5%E5%8F%A3%E8%AE%BE%E7%BD%AE%E6%8B%A6%E6%88%AA%E5%99%A8/","title":"给feign接口设置拦截器"},{"content":"先将配置类和常量类创建好 1 2 3 4 5 6 7 8 9 10 11 12 13 @Data @Component @ConfigurationProperties(prefix = \u0026#34;emqx.client\u0026#34;) public class EmqxProperties { private String clientId; private String username; private String password; private String serverURI; private int keepAliveInterval; private int connectionTimeout; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class EmqxConstants { /** 充电宝插入，柜机发布Topic消息， 服务器监听消息 */ public final static String TOPIC_POWERBANK_CONNECTED = \u0026#34;/sys/powerBank/connected\u0026#34;; /** 用户扫码，服务器发布Topic消息 柜机监听消息 */ public final static String TOPIC_SCAN_SUBMIT = \u0026#34;/sys/scan/submit/%s\u0026#34;; /** 充电宝弹出，柜机发布Topic消息，服务器监听消息 */ public final static String TOPIC_POWERBANK_UNLOCK = \u0026#34;/sys/powerBank/unlock\u0026#34;; /** 柜机属性上报，服务器监听消息 */ public final static String TOPIC_PROPERTY_POST = \u0026#34;/sys/property/post\u0026#34;; } 这里相关类的UML类图 接下来针对逐个类进行分析 首先是负责连接和发送emqx的EmqxClientWrapper , 这里比较重要的是MqttCallback mqttCallback 回调对象，这个是我们后面实现对topic动态的监听关键 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 @Component @Slf4j public class EmqxClientWrapper { @Autowired private EmqxProperties emqxProperties; @Autowired private MqttCallback mqttCallback; private MqttClient client; @PostConstruct private void init() { MqttClientPersistence mqttClientPersistence = new MemoryPersistence(); try { //新建客户端 参数：MQTT服务的地址，客户端名称，持久化 client = new MqttClient(emqxProperties.getServerURI(), emqxProperties.getClientId(), mqttClientPersistence); // 设置回调 client.setCallback(mqttCallback); // 建立连接 connect(); } catch (MqttException e) { log.info(\u0026#34;MqttClient创建失败\u0026#34;); throw new RuntimeException(e); } } private void connect() { try { MqttConnectOptions options = mqttConnectOptions(); client.connect(options); log.info(\u0026#34;连接成功。。。。。。。\u0026#34;); //订阅topic client.subscribe(new String[]{EmqxConstants.TOPIC_POWERBANK_CONNECTED, EmqxConstants.TOPIC_POWERBANK_UNLOCK, EmqxConstants.TOPIC_PROPERTY_POST}); } catch (MqttException e) { throw new RuntimeException(e); } } private MqttConnectOptions mqttConnectOptions() { MqttConnectOptions mqttConnectOptions = new MqttConnectOptions(); mqttConnectOptions.setPassword(emqxProperties.getPassword().toCharArray()); mqttConnectOptions.setUserName(emqxProperties.getUsername()); mqttConnectOptions.setAutomaticReconnect(true);//是否自动重新连接 mqttConnectOptions.setCleanSession(true);//是否清除之前的连接信息 mqttConnectOptions.setConnectionTimeout(emqxProperties.getConnectionTimeout());//连接超时时间 mqttConnectOptions.setKeepAliveInterval(emqxProperties.getKeepAliveInterval());//心跳 return mqttConnectOptions; } public void publish(String topic, String data) { MqttMessage mqttMessage = new MqttMessage(data.getBytes()); mqttMessage.setQos(2); try { client.publish(topic, mqttMessage); } catch (MqttException e) { log.error(\u0026#34;发送消息失败，topic:\u0026#34; + topic); throw new RuntimeException(e); } } } 假设我们有两个业务需求需要监听不同的topic 业务A\n1 2 3 4 5 6 7 8 @Component @Slf4j public class PowerBankConnectedHandler { @Override public void handleMessage(JSONObject message) { log.info(\u0026#34;handleMessage: {}\u0026#34;, message.toJSONString()); } } 业务B\n1 2 3 4 5 6 7 8 @Component @Slf4j public class PropertyPostHandler{ @Override public void handleMessage(JSONObject message) { log.info(\u0026#34;handleMessage: {}\u0026#34;, message.toJSONString()); } } 正常来说，我们会去创建MqttCallback实现类，然后注入业务A 和 业务 B对象，最后根据具体的topic判断调用相应业务类方法。\nbut \u0026hellip;.，这样就会在后续我们要加入业务C,D,E······时要不断的在MqttCallback实现类上加入对象和相应的判断。\n这样真是灾难， so 这里我们引入一个设计模式，借用工厂来创建好对象，然后MqttCallback实现类中去工厂类里面去拿对象，MqttCallback实现类中无需自行注入对象\n首先我们创建一个自定义注解(用于标记topic)和一个接口用于规范所有要使用emqx的业务 1 2 3 4 5 6 7 8 @Target({ElementType.TYPE}) @Retention(RetentionPolicy.RUNTIME) @Documented public @interface MyEmqx { String topic(); } 1 2 3 4 5 6 7 8 9 public interface MassageHandler { /** * 策略接口 * @param message */ void handleMessage(JSONObject message); } 然后有进化版的业务A、B，这样我们在工厂里利用多态的特性来实现MassageHandler实现类和topic的绑定 1 2 3 4 5 6 7 8 9 @Component @Slf4j @MyEmqx(topic = EmqxConstants.TOPIC_POWERBANK_CONNECTED) public class PowerBankConnectedHandler implements MassageHandler { @Override public void handleMessage(JSONObject message) { log.info(\u0026#34;handleMessage: {}\u0026#34;, message.toJSONString()); } } 1 2 3 4 5 6 7 8 9 @Component @Slf4j @MyEmqx(topic = EmqxConstants.TOPIC_POWERBANK_UNLOCK) public class PropertyPostHandler implements MassageHandler { @Override public void handleMessage(JSONObject message) { log.info(\u0026#34;handleMessage: {}\u0026#34;, message.toJSONString()); } } 重头戏来了，他就是我们的工厂类，考虑到后续可能存在不同的工厂(创建逻辑不一样)，所以可以先暂时将工厂接口化 1 2 3 4 5 public interface MessageHandlerFactory { MassageHandler getMassageHandler(String topic); } 具体的工厂实现类，该类实现了MessageHandlerFactory, ApplicationContextAware接口，ApplicationContextAware主要用于从spring容器中获取对象，然后在获取到相应对象上的注解属性实现动态绑定topic\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 @Service public class MessageHandlerFactoryImpl implements MessageHandlerFactory, ApplicationContextAware { Map\u0026lt;String, MassageHandler\u0026gt; massageHandlerBeanMap = new HashMap\u0026lt;\u0026gt;(); @Override public MassageHandler getMassageHandler(String topic) { return massageHandlerBeanMap.get(topic); } @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { Map\u0026lt;String, MassageHandler\u0026gt; beans = applicationContext.getBeansOfType(MassageHandler.class); for (MassageHandler massageHandler : beans.values()) { // 从 massageHandler 的类上查找 @MyEmqx 注解，并获取第一个找到的注解实例。 MyEmqx myEmqx = AnnotatedElementUtils.findAllMergedAnnotations(massageHandler.getClass(), MyEmqx.class).iterator().next(); if (myEmqx != null){ String topic = myEmqx.topic(); massageHandlerBeanMap.put(topic, massageHandler); } } } } 最后我们实现MqttCallback接口来实现消息的监听 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 @Component @Slf4j @AllArgsConstructor public class OnMessageCallback implements MqttCallback { private final MessageHandlerFactory messageHandlerFactoryImpl; @Override public void connectionLost(Throwable throwable) { // 连接丢失后，一般在这里面进行重连 log.warn(\u0026#34;连接断开，可以做重连\u0026#34; + throwable); } @Override public void messageArrived(String topic, MqttMessage message) { // subscribe后得到的消息会执行到这里面 log.info(\u0026#34;接收消息主题:\u0026#34; + topic); log.info(\u0026#34;接收消息Qos:\u0026#34; + message.getQos()); log.info(\u0026#34;接收消息内容:\u0026#34; + new String(message.getPayload())); //根据topic获取相应的消息处理类 MassageHandler massageHandler = messageHandlerFactoryImpl.getMassageHandler(topic); if (null != massageHandler) { String content = new String(message.getPayload()); massageHandler.handleMessage(JSONObject.parseObject(content)); } } @Override public void deliveryComplete(IMqttDeliveryToken token) { log.info(\u0026#34;deliveryComplete---------\u0026#34; + token.isComplete()); } } 这里我们可以看到我通过 MassageHandler massageHandler = messageHandlerFactoryImpl.getMassageHandler(topic);来获取业务类。这样在后续业务拓展的时候就只需要关注业务了，真是妙哉。\n","date":"2025-09-20T00:00:00Z","image":"https://zell.zone/p/%E4%BD%BF%E7%94%A8%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0%E8%BF%9E%E6%8E%A5emqx/img/1_hu_f32d488da08e3726.jpg","permalink":"https://zell.zone/p/%E4%BD%BF%E7%94%A8%E5%B7%A5%E5%8E%82%E6%A8%A1%E5%BC%8F%E5%AE%9E%E7%8E%B0%E8%BF%9E%E6%8E%A5emqx/","title":"使用工厂模式实现连接emqx"},{"content":"方案一：纯静态博客搭建（Hugo + Stack + Vercel） 这是最推荐的方式，完美复刻原博客。\n第一步：安装 Hugo 下载 Hugo： 前往 Hugo GitHub Releases 页面：https://github.com/gohugoio/hugo/releases 根据你的操作系统下载扩展版（extended版本，支持Sass/SCSS）。例如 Windows 就下载 hugo_extended_0.XXX.0_windows-amd64.zip。 安装： Windows：解压下载的ZIP文件，将里面的 hugo.exe 放到一个你喜欢的目录（如 C:\\Hugo\\bin），然后将该目录添加到系统的 PATH 环境变量中。 Mac：推荐使用 Homebrew：brew install hugo Linux：下载解压后，将二进制文件移动到 /usr/local/bin/ 即可。 验证：打开终端/命令提示符，输入 hugo version，如果显示版本号（且包含extended字样），说明安装成功。 第二步：创建本地博客项目 创建新站点：\n1 2 hugo new site my-java-blog cd my-java-blog 初始化 Git（为后续部署做准备）：\n1 git init 第三步：安装和配置 Stack 主题 将主题添加为子模块（这是Hugo官方推荐的方式）：\n1 git submodule add https://github.com/CaiJimmy/hugo-theme-stack/ themes/stack 这会将主题代码克隆到你的 themes/stack 目录下。\n基本配置：\n在项目根目录下，创建配置文件 config.yaml (或 config.toml)。YAML格式更易读，推荐使用。 将以下基础配置复制到 config.yaml 中： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 baseURL: \u0026#34;https://your-blog-domain.vercel.app/\u0026#34; # 稍后替换为你自己的域名 languageCode: \u0026#34;zh-cn\u0026#34; title: \u0026#34;我的Java技术博客\u0026#34; theme: \u0026#34;stack\u0026#34; # 设置默认内容语言 defaultContentLanguage: \u0026#39;zh\u0026#39; # 主题相关配置 params: # 网站副标题 subtitle: \u0026#34;探索编程与架构之美\u0026#34; # 首页模式：\u0026#39;grid\u0026#39; 网格 | \u0026#39;list\u0026#39; 列表 home_mode: \u0026#39;grid\u0026#39; # 主题颜色： \u0026#39;auto\u0026#39; | \u0026#39;light\u0026#39; | \u0026#39;dark\u0026#39; defaultTheme: \u0026#39;auto\u0026#39; # 菜单配置 menu: main: - identifier: \u0026#34;home\u0026#34; name: \u0026#34;首页\u0026#34; url: \u0026#34;/\u0026#34; weight: 1 - identifier: \u0026#34;about\u0026#34; name: \u0026#34;关于\u0026#34; url: \u0026#34;/about\u0026#34; weight: 2 # 评论系统（可选，后期可配置） # services: # disqus: # shortname: \u0026#34;your-disqus-shortname\u0026#34; # 谷歌分析（可选） # googleAnalytics: \u0026#34;G-XXXXXXXXXX\u0026#34; # 允许渲染 Emoji enableEmoji: true 第四步：创建你的第一篇文章 新建文章：\n1 hugo new posts/my-first-post.md 这会在 content/posts/ 目录下生成一个Markdown文件。\n编辑文章： 用任何文本编辑器打开 content/posts/my-first-post.md，内容如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 --- title: \u0026#34;我的第一篇文章\u0026#34; date: 2023-10-27 draft: false # 发布时改为 false tags: [\u0026#34;Java\u0026#34;, \u0026#34;Hugo\u0026#34;] categories: [\u0026#34;技术\u0026#34;] --- ## 欢迎使用 Hugo 这是一篇用 Markdown 写的文章。**加粗**，*斜体*，[链接](https://java.com)。 ​```java public class HelloWorld { public static void main(String[] args) { System.out.println(\u0026#34;Hello, Hugo and Java!\u0026#34;); } } 第五步：本地预览和调试 启动本地服务器：\n1 hugo server -D -D 参数表示包含草稿（draft: true）的文章。 查看博客： 在浏览器中打开 http://localhost:1313。你现在应该能看到和原博客风格几乎一样的网站了！你对代码和配置的任何修改都会实时热重载。\n第六步：部署到 Vercel（免费且高速） 将代码推送到 GitHub：\n在 GitHub 上创建一个新的代码仓库（如 my-java-blog）。 按照指引将你本地的代码推送上去。 注册并连接 Vercel：\n访问 Vercel 官网，使用 GitHub 账号注册。 点击 “Import Project” -\u0026gt; “Import Git Repository”，选择你刚创建的仓库。 一键部署：\nVercel 会自动检测到这是 Hugo 项目并配置好构建命令（hugo）和输出目录（public）。 你几乎不需要修改任何设置，直接点击 “Deploy”。 访问线上博客： 部署完成后，Vercel 会为你分配一个 *.vercel.app 的域名。你现在就有了一个和原博客一样的、全球高速访问的个人博客了！\n方案二：为静态博客添加 Java 后端（可选） 纯静态博客无法实现评论、点赞等动态功能。如果你需要这些，可以按以下架构添加一个独立的Java后端。\n架构图 1 2 3 4 5 6 用户浏览器 (访问博客) \u0026lt;-- 静态文件 (HTML, CSS, JS) --\u0026gt; Vercel (托管Hugo博客) | | (Ajax API 调用，如提交评论) | \\|/ Java后端API (Spring Boot) \u0026lt;--\u0026gt; 数据库 (MySQL/PostgreSQL) 实现步骤（以评论功能为例）： 创建 Spring Boot 项目：\n使用 Spring Initializr 创建一个新项目，选择 Web, JPA, PostgreSQL 等依赖。 设计评论实体和API：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 // Comment.java Entity @Entity @Data public class Comment { @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Long id; private String postUrl; // 通过文章URL关联静态博客的文章 private String author; private String content; private LocalDateTime createdAt; } // CommentController.java @RestController @RequestMapping(\u0026#34;/api/comments\u0026#34;) @CrossOrigin(origins = \u0026#34;https://your-blog-domain.vercel.app\u0026#34;) // 允许你的博客域名调用 public class CommentController { @Autowired private CommentRepository commentRepository; @GetMapping public List\u0026lt;Comment\u0026gt; getComments(@RequestParam String postUrl) { return commentRepository.findByPostUrlOrderByCreatedAtDesc(postUrl); } @PostMapping public Comment addComment(@RequestBody Comment comment) { comment.setCreatedAt(LocalDateTime.now()); return commentRepository.save(comment); } } 部署 Java 后端：\n你可以将打包好的Jar包部署到任何支持Java的云平台，如： 阿里云/腾讯云轻量应用服务器：性价比高，完全控制。 Railway / Render：新兴的部署平台，对开源项目有免费额度。 Heroku：老牌云应用平台。 在 Hugo 博客中调用 API：\n在你的Hugo主题模板（layouts/partials/comments.html）或使用自定义JS文件，添加Ajax代码来调用你的Java后端。 1 2 3 4 5 6 7 8 9 10 11 12 // 获取当前文章的URL const postUrl = window.location.pathname; // 从你的Java后端获取评论列表 fetch(`https://your-java-api.railway.app/api/comments?postUrl=${postUrl}`) .then(response =\u0026gt; response.json()) .then(comments =\u0026gt; { // 将评论渲染到页面上 }); // 处理用户提交评论的表单 // ... 提交到 POST /api/comments 最终建议 先从方案一开始：完美复刻你想要的博客，成本极低，流程顺畅。这是核心。 运行起来后，再根据实际需求，考虑是否要启动方案二，用Java去实现一些动态功能。绝大多数情况下，纯静态博客已经完全够用，评论等功能可以使用第三方的Utterances（基于GitHub Issues）或Giscus（基于GitHub Discussions）来替代自建Java后端，这样更简单。 ","date":"2025-09-19T00:00:00Z","image":"https://zell.zone/p/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/img/1_hu_9e4e9426a2fab57b.jpg","permalink":"https://zell.zone/p/%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA/","title":"博客搭建"}]